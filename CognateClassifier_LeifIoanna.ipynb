{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPo6xTFF09PX",
        "outputId": "1cd6a171-aac8-4392-afa4-00b9f3b174c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "#!pip install lingpy\n",
        "#import lingpy\n",
        "#from lingpy import ipa2tokens\n",
        "import re\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "torch.set_default_device(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s7sFvN-IcYr1"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "6YNbkDWOhJkL",
        "outputId": "5866087a-e1f5-4886-cefe-9dc0e6b8cf9f"
      },
      "outputs": [],
      "source": [
        "dat = pd.read_csv('data/ielexData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BSPctSOEsWls"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Language</th>\n",
              "      <th>Meaning</th>\n",
              "      <th>Phonological Form</th>\n",
              "      <th>cc</th>\n",
              "      <th>ASJP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>Greek</td>\n",
              "      <td>few</td>\n",
              "      <td>ˈliʝi</td>\n",
              "      <td>few:I</td>\n",
              "      <td>liSi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63</td>\n",
              "      <td>Bulgarian</td>\n",
              "      <td>few</td>\n",
              "      <td>ˈmaɫku</td>\n",
              "      <td>few:H</td>\n",
              "      <td>maLku</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65</td>\n",
              "      <td>Russian</td>\n",
              "      <td>few</td>\n",
              "      <td>'maɫɔ</td>\n",
              "      <td>few:H</td>\n",
              "      <td>maLo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>66</td>\n",
              "      <td>Polish</td>\n",
              "      <td>few</td>\n",
              "      <td>ˈmawɔ</td>\n",
              "      <td>few:H</td>\n",
              "      <td>mawo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>68</td>\n",
              "      <td>Ukrainian</td>\n",
              "      <td>few</td>\n",
              "      <td>ˈmaɫɔ</td>\n",
              "      <td>few:H</td>\n",
              "      <td>maLo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4479</th>\n",
              "      <td>124</td>\n",
              "      <td>French</td>\n",
              "      <td>head</td>\n",
              "      <td>tɛt</td>\n",
              "      <td>head:D</td>\n",
              "      <td>tEt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4480</th>\n",
              "      <td>135</td>\n",
              "      <td>Italian</td>\n",
              "      <td>head</td>\n",
              "      <td>'tɛsta</td>\n",
              "      <td>head:D</td>\n",
              "      <td>tEsta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4481</th>\n",
              "      <td>136</td>\n",
              "      <td>Romanian</td>\n",
              "      <td>head</td>\n",
              "      <td>kap</td>\n",
              "      <td>head:B</td>\n",
              "      <td>kap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4482</th>\n",
              "      <td>143</td>\n",
              "      <td>Breton</td>\n",
              "      <td>head</td>\n",
              "      <td>ˈpɛnː</td>\n",
              "      <td>head:E</td>\n",
              "      <td>pEn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4483</th>\n",
              "      <td>145</td>\n",
              "      <td>Irish</td>\n",
              "      <td>head</td>\n",
              "      <td>caːn̪ˠ, can̪ˠ</td>\n",
              "      <td>head:E</td>\n",
              "      <td>TanTan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4484 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0   Language Meaning Phonological Form      cc    ASJP\n",
              "0             11      Greek     few             ˈliʝi   few:I    liSi\n",
              "1             63  Bulgarian     few            ˈmaɫku   few:H   maLku\n",
              "2             65    Russian     few             'maɫɔ   few:H    maLo\n",
              "3             66     Polish     few             ˈmawɔ   few:H    mawo\n",
              "4             68  Ukrainian     few             ˈmaɫɔ   few:H    maLo\n",
              "...          ...        ...     ...               ...     ...     ...\n",
              "4479         124     French    head               tɛt  head:D     tEt\n",
              "4480         135    Italian    head            'tɛsta  head:D   tEsta\n",
              "4481         136   Romanian    head               kap  head:B     kap\n",
              "4482         143     Breton    head             ˈpɛnː  head:E     pEn\n",
              "4483         145      Irish    head     caːn̪ˠ, can̪ˠ  head:E  TanTan\n",
              "\n",
              "[4484 rows x 6 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SVRxPbTss04u"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Language</th>\n",
              "      <th>Meaning</th>\n",
              "      <th>Phonological Form</th>\n",
              "      <th>cc</th>\n",
              "      <th>ASJP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>Greek</td>\n",
              "      <td>few</td>\n",
              "      <td>ˈliʝi</td>\n",
              "      <td>few:I</td>\n",
              "      <td>liSi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63</td>\n",
              "      <td>Bulgarian</td>\n",
              "      <td>few</td>\n",
              "      <td>ˈmaɫku</td>\n",
              "      <td>few:H</td>\n",
              "      <td>maLku</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65</td>\n",
              "      <td>Russian</td>\n",
              "      <td>few</td>\n",
              "      <td>'maɫɔ</td>\n",
              "      <td>few:H</td>\n",
              "      <td>maLo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>66</td>\n",
              "      <td>Polish</td>\n",
              "      <td>few</td>\n",
              "      <td>ˈmawɔ</td>\n",
              "      <td>few:H</td>\n",
              "      <td>mawo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>68</td>\n",
              "      <td>Ukrainian</td>\n",
              "      <td>few</td>\n",
              "      <td>ˈmaɫɔ</td>\n",
              "      <td>few:H</td>\n",
              "      <td>maLo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>70</td>\n",
              "      <td>Czech</td>\n",
              "      <td>few</td>\n",
              "      <td>ˈmaːlɔ</td>\n",
              "      <td>few:H</td>\n",
              "      <td>malo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>79</td>\n",
              "      <td>Icelandic</td>\n",
              "      <td>few</td>\n",
              "      <td>ˈfauːɪr</td>\n",
              "      <td>few:F</td>\n",
              "      <td>fauir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>84</td>\n",
              "      <td>Swedish</td>\n",
              "      <td>few</td>\n",
              "      <td>foː</td>\n",
              "      <td>few:F</td>\n",
              "      <td>fo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>89</td>\n",
              "      <td>Danish</td>\n",
              "      <td>few</td>\n",
              "      <td>fɔˀ</td>\n",
              "      <td>few:F</td>\n",
              "      <td>fo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>93</td>\n",
              "      <td>English</td>\n",
              "      <td>few</td>\n",
              "      <td>fju:</td>\n",
              "      <td>few:F</td>\n",
              "      <td>fyu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>95</td>\n",
              "      <td>Dutch</td>\n",
              "      <td>few</td>\n",
              "      <td>'wɛinəχ</td>\n",
              "      <td>few:B</td>\n",
              "      <td>wEin3G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>104</td>\n",
              "      <td>German</td>\n",
              "      <td>few</td>\n",
              "      <td>'ve:nɪç</td>\n",
              "      <td>few:B</td>\n",
              "      <td>veniS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>110</td>\n",
              "      <td>Catalan</td>\n",
              "      <td>few</td>\n",
              "      <td>pɔk</td>\n",
              "      <td>few:F</td>\n",
              "      <td>pok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>112</td>\n",
              "      <td>Portuguese</td>\n",
              "      <td>few</td>\n",
              "      <td>ˈpo(ou)ku</td>\n",
              "      <td>few:F</td>\n",
              "      <td>poouku</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>113</td>\n",
              "      <td>Spanish</td>\n",
              "      <td>few</td>\n",
              "      <td>'poko</td>\n",
              "      <td>few:F</td>\n",
              "      <td>poko</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>119</td>\n",
              "      <td>French</td>\n",
              "      <td>few</td>\n",
              "      <td>pø</td>\n",
              "      <td>few:F</td>\n",
              "      <td>pe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>126</td>\n",
              "      <td>Italian</td>\n",
              "      <td>few</td>\n",
              "      <td>'pɔko</td>\n",
              "      <td>few:F</td>\n",
              "      <td>poko</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>134</td>\n",
              "      <td>Breton</td>\n",
              "      <td>few</td>\n",
              "      <td>ˈneːbøt</td>\n",
              "      <td>few:M</td>\n",
              "      <td>nebet</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0    Language Meaning Phonological Form     cc    ASJP\n",
              "0           11       Greek     few             ˈliʝi  few:I    liSi\n",
              "1           63   Bulgarian     few            ˈmaɫku  few:H   maLku\n",
              "2           65     Russian     few             'maɫɔ  few:H    maLo\n",
              "3           66      Polish     few             ˈmawɔ  few:H    mawo\n",
              "4           68   Ukrainian     few             ˈmaɫɔ  few:H    maLo\n",
              "5           70       Czech     few            ˈmaːlɔ  few:H    malo\n",
              "6           79   Icelandic     few           ˈfauːɪr  few:F   fauir\n",
              "7           84     Swedish     few               foː  few:F      fo\n",
              "8           89      Danish     few               fɔˀ  few:F      fo\n",
              "9           93     English     few              fju:  few:F     fyu\n",
              "10          95       Dutch     few           'wɛinəχ  few:B  wEin3G\n",
              "11         104      German     few           've:nɪç  few:B   veniS\n",
              "12         110     Catalan     few               pɔk  few:F     pok\n",
              "13         112  Portuguese     few         ˈpo(ou)ku  few:F  poouku\n",
              "14         113     Spanish     few             'poko  few:F    poko\n",
              "15         119      French     few                pø  few:F      pe\n",
              "16         126     Italian     few             'pɔko  few:F    poko\n",
              "17         134      Breton     few           ˈneːbøt  few:M   nebet"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat[dat['Meaning'] == 'few']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZuRw0ywqj_pi"
      },
      "outputs": [],
      "source": [
        "concepts = [re.sub(':.*', '', x) for x in dat['cc']]\n",
        "dat['concepts'] = concepts\n",
        "uniqueconcepts = np.unique(concepts)\n",
        "cognates = [list(re.sub('^.*:', '', x))[0] for x in dat['cc']]\n",
        "dat['cognate_char'] = cognates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IkLJo8SXlAsq"
      },
      "outputs": [],
      "source": [
        "source_words = []\n",
        "target_words = []\n",
        "label = []\n",
        "for concept in uniqueconcepts:\n",
        "  tmp_df = dat[dat['concepts'] == concept]\n",
        "  for word_idx in range(len(tmp_df)):\n",
        "    source_word = tmp_df['ASJP'].iloc[word_idx]\n",
        "    source_class = tmp_df['cognate_char'].iloc[word_idx]\n",
        "    if len(list(source_word)) < 11:\n",
        "      for word_idx2 in range(len(tmp_df)):\n",
        "        if word_idx != word_idx2:\n",
        "          target_word = tmp_df['ASJP'].iloc[word_idx2]\n",
        "          target_class = tmp_df['cognate_char'].iloc[word_idx2]\n",
        "          if len(list(target_word)) < 11:\n",
        "            if source_class == target_class:\n",
        "              label.append(1)\n",
        "            else:\n",
        "              label.append(0)\n",
        "            source_words.append(source_word)\n",
        "            target_words.append(target_word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TrFEwTjuo2dP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'exo'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source_words[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Aty0si5lrJSm"
      },
      "outputs": [],
      "source": [
        "charlens = []\n",
        "unique_characters = []\n",
        "for i in source_words:\n",
        "  charlens.append(len(list(i)))\n",
        "  for j in list(i):\n",
        "    unique_characters.append(j)\n",
        "unique_characters = ['PAD'] + np.unique(unique_characters).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c9rvCsAxvRkP"
      },
      "outputs": [],
      "source": [
        "maxlen = max(charlens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "E6_BhldMr7gC"
      },
      "outputs": [],
      "source": [
        "source_words_tokens = []\n",
        "target_words_tokens = []\n",
        "for j in range(len(source_words)):\n",
        "  source_tmp = [unique_characters.index(i) for i in list(source_words[j])]\n",
        "  target_tmp = [unique_characters.index(i) for i in list(target_words[j])]\n",
        "  source_tmp = source_tmp + [0 for x in range(maxlen-len(source_tmp))]\n",
        "  target_tmp = target_tmp + [0 for x in range(maxlen-len(target_tmp))]\n",
        "\n",
        "  source_words_tokens.append(source_tmp)\n",
        "  target_words_tokens.append(target_tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0yDt6ga1Unur"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([15, 33, 25, 0, 0, 0, 0, 0, 0, 0], [25, 23, 19, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source_words_tokens[0], target_words_tokens[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "USKXloHqU5qQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'o'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique_characters[25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "79Py6Q5ttJpi"
      },
      "outputs": [],
      "source": [
        "#indices = np.arange(len(source_words_tokens))\n",
        "#np.random.shuffle(indices)\n",
        "#split_index = int(0.9 * len(indices))\n",
        "#train_indices = indices[:split_index]\n",
        "#test_indices = indices[split_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ukL-LmvDti90"
      },
      "outputs": [],
      "source": [
        "#source_words_tokens_train = source_words_tokens[train_indices]\n",
        "#source_words_tokens_test = source_words_tokens[test_indices]\n",
        "#target_words_tokens_train = target_words_tokens[train_indices]\n",
        "#target_words_tokens_test = target_words_tokens[test_indices]\n",
        "#label_train = label[train_indices]\n",
        "#label_test = label[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "m8XwOsXduL5f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "source_train, source_test, target_train, target_test, label_train, label_test = train_test_split(source_words_tokens, target_words_tokens, label, test_size=0.1, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lehKemrDs1Y4"
      },
      "outputs": [],
      "source": [
        "source_train_tensor = torch.tensor(source_train, dtype=torch.long, device=device)\n",
        "source_test_tensor = torch.tensor(source_test, dtype=torch.long, device=device)\n",
        "target_train_tensor = torch.tensor(target_train, dtype=torch.long, device=device)\n",
        "target_test_tensor = torch.tensor(target_test, dtype=torch.long, device=device)\n",
        "label_train_tensor = torch.tensor(label_train, dtype=torch.int, device=device)\n",
        "label_test_tensor = torch.tensor(label_test, dtype=torch.int, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7MP_JlcJxwrl"
      },
      "outputs": [],
      "source": [
        "train_dataset = TensorDataset(source_train_tensor, target_train_tensor, label_train_tensor)\n",
        "test_dataset = TensorDataset(source_test_tensor, target_test_tensor, label_test_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dU6TVNvAyID-"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, generator=torch.Generator(device='cuda'))\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size, generator=torch.Generator(device='cuda'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBhBmSPnxdim"
      },
      "source": [
        "Next step: NN that takes in both words, converts them to embeddings and predicts whether they are cognates (yes/no) = (1/0), sigmoid classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "i8zkOA4FgdcO"
      },
      "outputs": [],
      "source": [
        "class SiameseNet(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=64, hidden_dim=128, dropout = .2):\n",
        "        super(SiameseNet, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
        "        self.lin1 = nn.Linear(hidden_dim, 64)\n",
        "        self.lin2 = nn.Linear(64, 1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "    #def forward_once(self, x):\n",
        "    #    x = self.embedding(x)\n",
        "    #    _, (hidden, _) = self.lstm(x)\n",
        "    #    return hidden[-1]\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1_emb = self.embedding(input1)\n",
        "        output2_emb = self.embedding(input2)\n",
        "        out_state1, (hidden1, _) = self.lstm(output1_emb)\n",
        "        out_state2, (hidden2, _) = self.lstm(output2_emb)\n",
        "        output1 = hidden1[-1]\n",
        "        output2 = hidden2[-1]\n",
        "        diff = torch.abs(output1 - output2)\n",
        "        out = self.dropout(self.relu(self.lin1(diff)))\n",
        "        out = self.lin2(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4iOIqTKg4B4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1fU-QWTIg064"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\lsm0147\\Documents\\Cognates\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(unique_characters)\n",
        "\n",
        "model = SiameseNet(vocab_size)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cdxP_hauX-YA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.3619e-04, 2.9999e+00], device='cuda:0')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tan = nn.Tanh()\n",
        "sigmoid = nn.Sigmoid()\n",
        "mydatavalue = 3\n",
        "torch.tensor([mydatavalue, mydatavalue]) * sigmoid(torch.tensor([-10, 10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sJLp3kGfWfed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Loss: 0.5311, Train Accuracy: 65.60%, Test Accuracy: 68.79%\n",
            "Epoch 2/2, Loss: 0.3997, Train Accuracy: 85.32%, Test Accuracy: 84.52%\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 2\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for source_batch, target_batch, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        source_batch = source_batch.to(device)\n",
        "        target_batch = target_batch.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(source_batch, target_batch).squeeze()\n",
        "        loss = criterion(outputs, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    outputs = model(source_batch, target_batch).squeeze()\n",
        "    predicted = (outputs > 0.5).int()\n",
        "    correct_train += (predicted == labels).sum().item()\n",
        "    total_train += labels.size(0)\n",
        "\n",
        "    model.eval()\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for source_batch, target_batch, labels in test_loader:\n",
        "            source_batch = source_batch.to(device)\n",
        "            target_batch = target_batch.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(source_batch, target_batch).squeeze()\n",
        "            predicted = (outputs > 0.5).int()\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "            total_test += labels.size(0)\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Train Accuracy: {100 * correct_train / total_train:.2f}%, Test Accuracy: {100 * correct_test / total_test:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "444sINfIg4Rt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 84.52%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for source_batch, target_batch, labels in test_loader:\n",
        "        source_batch = source_batch.to(device)\n",
        "        target_batch = target_batch.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = model(source_batch, target_batch).squeeze()\n",
        "        predicted = (outputs > 0.5).int()\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Fpn7DApLim6u"
      },
      "outputs": [],
      "source": [
        "def predict_cognate(word1, word2):\n",
        "    def encode(word):\n",
        "        encoded = [unique_characters.index(c)+1 for c in word]\n",
        "        return encoded + [0] * (maxlen - len(encoded))\n",
        "\n",
        "    model.eval()\n",
        "    w1 = torch.tensor([encode(word1)], dtype=torch.long, device=device)\n",
        "    w2 = torch.tensor([encode(word2)], dtype=torch.long, device=device)\n",
        "    with torch.no_grad():\n",
        "        output = model(w1, w2)\n",
        "    return \"Yes\" if output.item() > 0.5 else \"No\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VUKIx6TTjKlQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'No'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_cognate(\"maLo\", \"fauir\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EmixS16bjMI1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'No'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_cognate(\"maLo\", \"mawo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnyQL28rjL1M"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "r9-ZCrmSkZg7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SimpleCognateDataset(Dataset):\n",
        "    def __init__(self, data, unique_characters, maxlen):\n",
        "        self.data = data\n",
        "        self.char_to_idx = {char: i+1 for i, char in enumerate(unique_characters)}\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def encode_word(self, word):\n",
        "        #This is way faster than the \"proper method\"\n",
        "        #Because all the data on the cpu device, so making a tensor would send it to the gpu, then pull it from the gpu, then send it again\n",
        "        #Maybe if we could make this dataset once and put it on the gpu once, then it would be way faster\n",
        "        encoded = [self.char_to_idx.get(c, 0) for c in word]\n",
        "        return encoded + [0] * (self.maxlen - len(encoded))\n",
        "    \n",
        "        #encoded = [self.char_to_idx.get(c, 0) for c in word]\n",
        "        #return nn.functional.pad(torch.tensor(encoded, dtype=torch.long), (0, self.maxlen - len(encoded)), value=0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        word1, word2, label = self.data[idx]\n",
        "        return (\n",
        "            torch.tensor(self.encode_word(word1), dtype=torch.long, device=device),\n",
        "            torch.tensor(self.encode_word(word2), dtype=torch.long, device=device),\n",
        "            torch.tensor(label, dtype=torch.float, device=device)\n",
        "        )\n",
        "\n",
        "class SimplePairNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=64, hidden_dim=128):\n",
        "        super(SimplePairNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode_word(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "        return hidden[-1]\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        enc1 = self.encode_word(input1)\n",
        "        enc2 = self.encode_word(input2)\n",
        "        combined = torch.cat([enc1, enc2], dim=1)\n",
        "        return self.fc(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meaning</th>\n",
              "      <th>word</th>\n",
              "      <th>cognate_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>few</td>\n",
              "      <td>ˈliʝi</td>\n",
              "      <td>few:I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>few</td>\n",
              "      <td>ˈmaɫku</td>\n",
              "      <td>few:H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>few</td>\n",
              "      <td>'maɫɔ</td>\n",
              "      <td>few:H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>few</td>\n",
              "      <td>ˈmawɔ</td>\n",
              "      <td>few:H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>few</td>\n",
              "      <td>ˈmaɫɔ</td>\n",
              "      <td>few:H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4479</th>\n",
              "      <td>head</td>\n",
              "      <td>tɛt</td>\n",
              "      <td>head:D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4480</th>\n",
              "      <td>head</td>\n",
              "      <td>'tɛsta</td>\n",
              "      <td>head:D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4481</th>\n",
              "      <td>head</td>\n",
              "      <td>kap</td>\n",
              "      <td>head:B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4482</th>\n",
              "      <td>head</td>\n",
              "      <td>ˈpɛnː</td>\n",
              "      <td>head:E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4483</th>\n",
              "      <td>head</td>\n",
              "      <td>caːn̪ˠ, can̪ˠ</td>\n",
              "      <td>head:E</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4484 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     meaning           word cognate_class\n",
              "0        few          ˈliʝi         few:I\n",
              "1        few         ˈmaɫku         few:H\n",
              "2        few          'maɫɔ         few:H\n",
              "3        few          ˈmawɔ         few:H\n",
              "4        few          ˈmaɫɔ         few:H\n",
              "...      ...            ...           ...\n",
              "4479    head            tɛt        head:D\n",
              "4480    head         'tɛsta        head:D\n",
              "4481    head            kap        head:B\n",
              "4482    head          ˈpɛnː        head:E\n",
              "4483    head  caːn̪ˠ, can̪ˠ        head:E\n",
              "\n",
              "[4484 rows x 3 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"data/ielexData.csv\")\n",
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "\n",
        "df = pd.read_csv(\"data/ielexData.csv\")\n",
        "\n",
        "df = df[['Meaning', 'Phonological Form', 'cc']].dropna()\n",
        "df.columns = ['meaning', 'word', 'cognate_class']\n",
        "\n",
        "pairs = []\n",
        "\n",
        "for _, group in df.groupby('meaning'):\n",
        "    entries = group.to_dict('records')\n",
        "    for w1, w2 in combinations(entries, 2):\n",
        "        word1 = str(w1['word'])\n",
        "        word2 = str(w2['word'])\n",
        "        label = int(w1['cognate_class'] == w2['cognate_class'])\n",
        "        pairs.append((word1, word2, label))\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('e̞ˈɣo̞', \"'ɑmi:\", 1),\n",
              " ('e̞ˈɣo̞', 'mɛ̃', 1),\n",
              " ('e̞ˈɣo̞', 'as', 1),\n",
              " ('e̞ˈɣo̞', 'ja', 1),\n",
              " ('e̞ˈɣo̞', 'ja', 1),\n",
              " ('e̞ˈɣo̞', 'ja', 1),\n",
              " ('e̞ˈɣo̞', 'jaː', 1),\n",
              " ('e̞ˈɣo̞', 'ɐʃ', 1),\n",
              " ('e̞ˈɣo̞', 'jɛɣ', 1),\n",
              " ('e̞ˈɣo̞', 'jɑːɡ, jɑː', 1),\n",
              " ('e̞ˈɣo̞', 'jɑj', 1),\n",
              " ('e̞ˈɣo̞', 'aɪ', 1),\n",
              " ('e̞ˈɣo̞', 'ɪk', 1),\n",
              " ('e̞ˈɣo̞', 'ɪç', 1),\n",
              " ('e̞ˈɣo̞', 'ʒɔ, jɔ', 1),\n",
              " ('e̞ˈɣo̞', 'eu', 1),\n",
              " ('e̞ˈɣo̞', 'ʝo', 1),\n",
              " ('e̞ˈɣo̞', 'ʒə', 1),\n",
              " ('e̞ˈɣo̞', \"'io\", 1),\n",
              " ('e̞ˈɣo̞', 'jew, jo', 1),\n",
              " ('e̞ˈɣo̞', 'ˈmeː', 0),\n",
              " ('e̞ˈɣo̞', 'miː, viː', 0),\n",
              " ('e̞ˈɣo̞', 'mʲeː', 0),\n",
              " (\"'ɑmi:\", 'mɛ̃', 1),\n",
              " (\"'ɑmi:\", 'as', 1),\n",
              " (\"'ɑmi:\", 'ja', 1),\n",
              " (\"'ɑmi:\", 'ja', 1),\n",
              " (\"'ɑmi:\", 'ja', 1),\n",
              " (\"'ɑmi:\", 'jaː', 1),\n",
              " (\"'ɑmi:\", 'ɐʃ', 1),\n",
              " (\"'ɑmi:\", 'jɛɣ', 1),\n",
              " (\"'ɑmi:\", 'jɑːɡ, jɑː', 1),\n",
              " (\"'ɑmi:\", 'jɑj', 1),\n",
              " (\"'ɑmi:\", 'aɪ', 1),\n",
              " (\"'ɑmi:\", 'ɪk', 1),\n",
              " (\"'ɑmi:\", 'ɪç', 1),\n",
              " (\"'ɑmi:\", 'ʒɔ, jɔ', 1),\n",
              " (\"'ɑmi:\", 'eu', 1),\n",
              " (\"'ɑmi:\", 'ʝo', 1),\n",
              " (\"'ɑmi:\", 'ʒə', 1),\n",
              " (\"'ɑmi:\", \"'io\", 1),\n",
              " (\"'ɑmi:\", 'jew, jo', 1),\n",
              " (\"'ɑmi:\", 'ˈmeː', 0),\n",
              " (\"'ɑmi:\", 'miː, viː', 0),\n",
              " (\"'ɑmi:\", 'mʲeː', 0),\n",
              " ('mɛ̃', 'as', 1),\n",
              " ('mɛ̃', 'ja', 1),\n",
              " ('mɛ̃', 'ja', 1),\n",
              " ('mɛ̃', 'ja', 1),\n",
              " ('mɛ̃', 'jaː', 1),\n",
              " ('mɛ̃', 'ɐʃ', 1),\n",
              " ('mɛ̃', 'jɛɣ', 1),\n",
              " ('mɛ̃', 'jɑːɡ, jɑː', 1),\n",
              " ('mɛ̃', 'jɑj', 1),\n",
              " ('mɛ̃', 'aɪ', 1),\n",
              " ('mɛ̃', 'ɪk', 1),\n",
              " ('mɛ̃', 'ɪç', 1),\n",
              " ('mɛ̃', 'ʒɔ, jɔ', 1),\n",
              " ('mɛ̃', 'eu', 1),\n",
              " ('mɛ̃', 'ʝo', 1),\n",
              " ('mɛ̃', 'ʒə', 1),\n",
              " ('mɛ̃', \"'io\", 1),\n",
              " ('mɛ̃', 'jew, jo', 1),\n",
              " ('mɛ̃', 'ˈmeː', 0),\n",
              " ('mɛ̃', 'miː, viː', 0),\n",
              " ('mɛ̃', 'mʲeː', 0),\n",
              " ('as', 'ja', 1),\n",
              " ('as', 'ja', 1),\n",
              " ('as', 'ja', 1),\n",
              " ('as', 'jaː', 1),\n",
              " ('as', 'ɐʃ', 1),\n",
              " ('as', 'jɛɣ', 1),\n",
              " ('as', 'jɑːɡ, jɑː', 1),\n",
              " ('as', 'jɑj', 1),\n",
              " ('as', 'aɪ', 1),\n",
              " ('as', 'ɪk', 1),\n",
              " ('as', 'ɪç', 1),\n",
              " ('as', 'ʒɔ, jɔ', 1),\n",
              " ('as', 'eu', 1),\n",
              " ('as', 'ʝo', 1),\n",
              " ('as', 'ʒə', 1),\n",
              " ('as', \"'io\", 1),\n",
              " ('as', 'jew, jo', 1),\n",
              " ('as', 'ˈmeː', 0),\n",
              " ('as', 'miː, viː', 0),\n",
              " ('as', 'mʲeː', 0),\n",
              " ('ja', 'ja', 1),\n",
              " ('ja', 'ja', 1),\n",
              " ('ja', 'jaː', 1),\n",
              " ('ja', 'ɐʃ', 1),\n",
              " ('ja', 'jɛɣ', 1),\n",
              " ('ja', 'jɑːɡ, jɑː', 1),\n",
              " ('ja', 'jɑj', 1),\n",
              " ('ja', 'aɪ', 1),\n",
              " ('ja', 'ɪk', 1),\n",
              " ('ja', 'ɪç', 1),\n",
              " ('ja', 'ʒɔ, jɔ', 1),\n",
              " ('ja', 'eu', 1),\n",
              " ('ja', 'ʝo', 1),\n",
              " ('ja', 'ʒə', 1),\n",
              " ('ja', \"'io\", 1),\n",
              " ('ja', 'jew, jo', 1),\n",
              " ('ja', 'ˈmeː', 0),\n",
              " ('ja', 'miː, viː', 0),\n",
              " ('ja', 'mʲeː', 0),\n",
              " ('ja', 'ja', 1),\n",
              " ('ja', 'jaː', 1),\n",
              " ('ja', 'ɐʃ', 1),\n",
              " ('ja', 'jɛɣ', 1),\n",
              " ('ja', 'jɑːɡ, jɑː', 1),\n",
              " ('ja', 'jɑj', 1),\n",
              " ('ja', 'aɪ', 1),\n",
              " ('ja', 'ɪk', 1),\n",
              " ('ja', 'ɪç', 1),\n",
              " ('ja', 'ʒɔ, jɔ', 1),\n",
              " ('ja', 'eu', 1),\n",
              " ('ja', 'ʝo', 1),\n",
              " ('ja', 'ʒə', 1),\n",
              " ('ja', \"'io\", 1),\n",
              " ('ja', 'jew, jo', 1),\n",
              " ('ja', 'ˈmeː', 0),\n",
              " ('ja', 'miː, viː', 0),\n",
              " ('ja', 'mʲeː', 0),\n",
              " ('ja', 'jaː', 1),\n",
              " ('ja', 'ɐʃ', 1),\n",
              " ('ja', 'jɛɣ', 1),\n",
              " ('ja', 'jɑːɡ, jɑː', 1),\n",
              " ('ja', 'jɑj', 1),\n",
              " ('ja', 'aɪ', 1),\n",
              " ('ja', 'ɪk', 1),\n",
              " ('ja', 'ɪç', 1),\n",
              " ('ja', 'ʒɔ, jɔ', 1),\n",
              " ('ja', 'eu', 1),\n",
              " ('ja', 'ʝo', 1),\n",
              " ('ja', 'ʒə', 1),\n",
              " ('ja', \"'io\", 1),\n",
              " ('ja', 'jew, jo', 1),\n",
              " ('ja', 'ˈmeː', 0),\n",
              " ('ja', 'miː, viː', 0),\n",
              " ('ja', 'mʲeː', 0),\n",
              " ('jaː', 'ɐʃ', 1),\n",
              " ('jaː', 'jɛɣ', 1),\n",
              " ('jaː', 'jɑːɡ, jɑː', 1),\n",
              " ('jaː', 'jɑj', 1),\n",
              " ('jaː', 'aɪ', 1),\n",
              " ('jaː', 'ɪk', 1),\n",
              " ('jaː', 'ɪç', 1),\n",
              " ('jaː', 'ʒɔ, jɔ', 1),\n",
              " ('jaː', 'eu', 1),\n",
              " ('jaː', 'ʝo', 1),\n",
              " ('jaː', 'ʒə', 1),\n",
              " ('jaː', \"'io\", 1),\n",
              " ('jaː', 'jew, jo', 1),\n",
              " ('jaː', 'ˈmeː', 0),\n",
              " ('jaː', 'miː, viː', 0),\n",
              " ('jaː', 'mʲeː', 0),\n",
              " ('ɐʃ', 'jɛɣ', 1),\n",
              " ('ɐʃ', 'jɑːɡ, jɑː', 1),\n",
              " ('ɐʃ', 'jɑj', 1),\n",
              " ('ɐʃ', 'aɪ', 1),\n",
              " ('ɐʃ', 'ɪk', 1),\n",
              " ('ɐʃ', 'ɪç', 1),\n",
              " ('ɐʃ', 'ʒɔ, jɔ', 1),\n",
              " ('ɐʃ', 'eu', 1),\n",
              " ('ɐʃ', 'ʝo', 1),\n",
              " ('ɐʃ', 'ʒə', 1),\n",
              " ('ɐʃ', \"'io\", 1),\n",
              " ('ɐʃ', 'jew, jo', 1),\n",
              " ('ɐʃ', 'ˈmeː', 0),\n",
              " ('ɐʃ', 'miː, viː', 0),\n",
              " ('ɐʃ', 'mʲeː', 0),\n",
              " ('jɛɣ', 'jɑːɡ, jɑː', 1),\n",
              " ('jɛɣ', 'jɑj', 1),\n",
              " ('jɛɣ', 'aɪ', 1),\n",
              " ('jɛɣ', 'ɪk', 1),\n",
              " ('jɛɣ', 'ɪç', 1),\n",
              " ('jɛɣ', 'ʒɔ, jɔ', 1),\n",
              " ('jɛɣ', 'eu', 1),\n",
              " ('jɛɣ', 'ʝo', 1),\n",
              " ('jɛɣ', 'ʒə', 1),\n",
              " ('jɛɣ', \"'io\", 1),\n",
              " ('jɛɣ', 'jew, jo', 1),\n",
              " ('jɛɣ', 'ˈmeː', 0),\n",
              " ('jɛɣ', 'miː, viː', 0),\n",
              " ('jɛɣ', 'mʲeː', 0),\n",
              " ('jɑːɡ, jɑː', 'jɑj', 1),\n",
              " ('jɑːɡ, jɑː', 'aɪ', 1),\n",
              " ('jɑːɡ, jɑː', 'ɪk', 1),\n",
              " ('jɑːɡ, jɑː', 'ɪç', 1),\n",
              " ('jɑːɡ, jɑː', 'ʒɔ, jɔ', 1),\n",
              " ('jɑːɡ, jɑː', 'eu', 1),\n",
              " ('jɑːɡ, jɑː', 'ʝo', 1),\n",
              " ('jɑːɡ, jɑː', 'ʒə', 1),\n",
              " ('jɑːɡ, jɑː', \"'io\", 1),\n",
              " ('jɑːɡ, jɑː', 'jew, jo', 1),\n",
              " ('jɑːɡ, jɑː', 'ˈmeː', 0),\n",
              " ('jɑːɡ, jɑː', 'miː, viː', 0),\n",
              " ('jɑːɡ, jɑː', 'mʲeː', 0),\n",
              " ('jɑj', 'aɪ', 1),\n",
              " ('jɑj', 'ɪk', 1),\n",
              " ('jɑj', 'ɪç', 1),\n",
              " ('jɑj', 'ʒɔ, jɔ', 1),\n",
              " ('jɑj', 'eu', 1),\n",
              " ('jɑj', 'ʝo', 1),\n",
              " ('jɑj', 'ʒə', 1),\n",
              " ('jɑj', \"'io\", 1),\n",
              " ('jɑj', 'jew, jo', 1),\n",
              " ('jɑj', 'ˈmeː', 0),\n",
              " ('jɑj', 'miː, viː', 0),\n",
              " ('jɑj', 'mʲeː', 0),\n",
              " ('aɪ', 'ɪk', 1),\n",
              " ('aɪ', 'ɪç', 1),\n",
              " ('aɪ', 'ʒɔ, jɔ', 1),\n",
              " ('aɪ', 'eu', 1),\n",
              " ('aɪ', 'ʝo', 1),\n",
              " ('aɪ', 'ʒə', 1),\n",
              " ('aɪ', \"'io\", 1),\n",
              " ('aɪ', 'jew, jo', 1),\n",
              " ('aɪ', 'ˈmeː', 0),\n",
              " ('aɪ', 'miː, viː', 0),\n",
              " ('aɪ', 'mʲeː', 0),\n",
              " ('ɪk', 'ɪç', 1),\n",
              " ('ɪk', 'ʒɔ, jɔ', 1),\n",
              " ('ɪk', 'eu', 1),\n",
              " ('ɪk', 'ʝo', 1),\n",
              " ('ɪk', 'ʒə', 1),\n",
              " ('ɪk', \"'io\", 1),\n",
              " ('ɪk', 'jew, jo', 1),\n",
              " ('ɪk', 'ˈmeː', 0),\n",
              " ('ɪk', 'miː, viː', 0),\n",
              " ('ɪk', 'mʲeː', 0),\n",
              " ('ɪç', 'ʒɔ, jɔ', 1),\n",
              " ('ɪç', 'eu', 1),\n",
              " ('ɪç', 'ʝo', 1),\n",
              " ('ɪç', 'ʒə', 1),\n",
              " ('ɪç', \"'io\", 1),\n",
              " ('ɪç', 'jew, jo', 1),\n",
              " ('ɪç', 'ˈmeː', 0),\n",
              " ('ɪç', 'miː, viː', 0),\n",
              " ('ɪç', 'mʲeː', 0),\n",
              " ('ʒɔ, jɔ', 'eu', 1),\n",
              " ('ʒɔ, jɔ', 'ʝo', 1),\n",
              " ('ʒɔ, jɔ', 'ʒə', 1),\n",
              " ('ʒɔ, jɔ', \"'io\", 1),\n",
              " ('ʒɔ, jɔ', 'jew, jo', 1),\n",
              " ('ʒɔ, jɔ', 'ˈmeː', 0),\n",
              " ('ʒɔ, jɔ', 'miː, viː', 0),\n",
              " ('ʒɔ, jɔ', 'mʲeː', 0),\n",
              " ('eu', 'ʝo', 1),\n",
              " ('eu', 'ʒə', 1),\n",
              " ('eu', \"'io\", 1),\n",
              " ('eu', 'jew, jo', 1),\n",
              " ('eu', 'ˈmeː', 0),\n",
              " ('eu', 'miː, viː', 0),\n",
              " ('eu', 'mʲeː', 0),\n",
              " ('ʝo', 'ʒə', 1),\n",
              " ('ʝo', \"'io\", 1),\n",
              " ('ʝo', 'jew, jo', 1),\n",
              " ('ʝo', 'ˈmeː', 0),\n",
              " ('ʝo', 'miː, viː', 0),\n",
              " ('ʝo', 'mʲeː', 0),\n",
              " ('ʒə', \"'io\", 1),\n",
              " ('ʒə', 'jew, jo', 1),\n",
              " ('ʒə', 'ˈmeː', 0),\n",
              " ('ʒə', 'miː, viː', 0),\n",
              " ('ʒə', 'mʲeː', 0),\n",
              " (\"'io\", 'jew, jo', 1),\n",
              " (\"'io\", 'ˈmeː', 0),\n",
              " (\"'io\", 'miː, viː', 0),\n",
              " (\"'io\", 'mʲeː', 0),\n",
              " ('jew, jo', 'ˈmeː', 0),\n",
              " ('jew, jo', 'miː, viː', 0),\n",
              " ('jew, jo', 'mʲeː', 0),\n",
              " ('ˈmeː', 'miː, viː', 1),\n",
              " ('ˈmeː', 'mʲeː', 1),\n",
              " ('miː, viː', 'mʲeː', 1),\n",
              " ('pas', 'ˈo̞lo̞s', 0),\n",
              " ('pas', 'ˈfsitʃki', 0),\n",
              " ('pas', 'vsʲɛ', 0),\n",
              " ('pas', 'ˈfʂɘ̟stsɘ̟', 0),\n",
              " ('pas', 'ʋsi', 0),\n",
              " ('pas', 'ˈfʃɪxɲɪ', 0),\n",
              " ('pas', 'ˈʋʲɪskɐs', 0),\n",
              " ('pas', 'ˈad̥lɪr', 0),\n",
              " ('pas', 'ˈàlːa', 0),\n",
              " ('pas', 'ˈalə', 0),\n",
              " ('pas', 'ɔ:l', 0),\n",
              " ('pas', \"'ɑlə\", 0),\n",
              " ('pas', \"'alə\", 0),\n",
              " ('pas', 'tot', 0),\n",
              " ('pas', 'ˈtoðu', 0),\n",
              " ('pas', \"'toðo\", 0),\n",
              " ('pas', 'tu', 0),\n",
              " ('pas', \"'tutto\", 0),\n",
              " ('pas', 'ˈɔlː', 0),\n",
              " ('ˈo̞lo̞s', 'ˈfsitʃki', 0),\n",
              " ('ˈo̞lo̞s', 'vsʲɛ', 0),\n",
              " ('ˈo̞lo̞s', 'ˈfʂɘ̟stsɘ̟', 0),\n",
              " ('ˈo̞lo̞s', 'ʋsi', 0),\n",
              " ('ˈo̞lo̞s', 'ˈfʃɪxɲɪ', 0),\n",
              " ('ˈo̞lo̞s', 'ˈʋʲɪskɐs', 0),\n",
              " ('ˈo̞lo̞s', 'ˈad̥lɪr', 0),\n",
              " ('ˈo̞lo̞s', 'ˈàlːa', 0),\n",
              " ('ˈo̞lo̞s', 'ˈalə', 0),\n",
              " ('ˈo̞lo̞s', 'ɔ:l', 0),\n",
              " ('ˈo̞lo̞s', \"'ɑlə\", 0),\n",
              " ('ˈo̞lo̞s', \"'alə\", 0),\n",
              " ('ˈo̞lo̞s', 'tot', 0),\n",
              " ('ˈo̞lo̞s', 'ˈtoðu', 0),\n",
              " ('ˈo̞lo̞s', \"'toðo\", 0),\n",
              " ('ˈo̞lo̞s', 'tu', 0),\n",
              " ('ˈo̞lo̞s', \"'tutto\", 0),\n",
              " ('ˈo̞lo̞s', 'ˈɔlː', 1),\n",
              " ('ˈfsitʃki', 'vsʲɛ', 1),\n",
              " ('ˈfsitʃki', 'ˈfʂɘ̟stsɘ̟', 1),\n",
              " ('ˈfsitʃki', 'ʋsi', 1),\n",
              " ('ˈfsitʃki', 'ˈfʃɪxɲɪ', 1),\n",
              " ('ˈfsitʃki', 'ˈʋʲɪskɐs', 1),\n",
              " ('ˈfsitʃki', 'ˈad̥lɪr', 0),\n",
              " ('ˈfsitʃki', 'ˈàlːa', 0),\n",
              " ('ˈfsitʃki', 'ˈalə', 0),\n",
              " ('ˈfsitʃki', 'ɔ:l', 0),\n",
              " ('ˈfsitʃki', \"'ɑlə\", 0),\n",
              " ('ˈfsitʃki', \"'alə\", 0),\n",
              " ('ˈfsitʃki', 'tot', 0),\n",
              " ('ˈfsitʃki', 'ˈtoðu', 0),\n",
              " ('ˈfsitʃki', \"'toðo\", 0),\n",
              " ('ˈfsitʃki', 'tu', 0),\n",
              " ('ˈfsitʃki', \"'tutto\", 0),\n",
              " ('ˈfsitʃki', 'ˈɔlː', 0),\n",
              " ('vsʲɛ', 'ˈfʂɘ̟stsɘ̟', 1),\n",
              " ('vsʲɛ', 'ʋsi', 1),\n",
              " ('vsʲɛ', 'ˈfʃɪxɲɪ', 1),\n",
              " ('vsʲɛ', 'ˈʋʲɪskɐs', 1),\n",
              " ('vsʲɛ', 'ˈad̥lɪr', 0),\n",
              " ('vsʲɛ', 'ˈàlːa', 0),\n",
              " ('vsʲɛ', 'ˈalə', 0),\n",
              " ('vsʲɛ', 'ɔ:l', 0),\n",
              " ('vsʲɛ', \"'ɑlə\", 0),\n",
              " ('vsʲɛ', \"'alə\", 0),\n",
              " ('vsʲɛ', 'tot', 0),\n",
              " ('vsʲɛ', 'ˈtoðu', 0),\n",
              " ('vsʲɛ', \"'toðo\", 0),\n",
              " ('vsʲɛ', 'tu', 0),\n",
              " ('vsʲɛ', \"'tutto\", 0),\n",
              " ('vsʲɛ', 'ˈɔlː', 0),\n",
              " ('ˈfʂɘ̟stsɘ̟', 'ʋsi', 1),\n",
              " ('ˈfʂɘ̟stsɘ̟', 'ˈfʃɪxɲɪ', 1),\n",
              " ('ˈfʂɘ̟stsɘ̟', 'ˈʋʲɪskɐs', 1),\n",
              " ('ˈfʂɘ̟stsɘ̟', 'ˈad̥lɪr', 0),\n",
              " ('ˈfʂɘ̟stsɘ̟', 'ˈàlːa', 0),\n",
              " ('ˈfʂɘ̟stsɘ̟', 'ˈalə', 0),\n",
              " ('ˈfʂɘ̟stsɘ̟', 'ɔ:l', 0),\n",
              " ('ˈfʂɘ̟stsɘ̟', \"'ɑlə\", 0),\n",
              " ('ˈfʂɘ̟stsɘ̟', \"'alə\", 0),\n",
              " ('ˈfʂɘ̟stsɘ̟', 'tot', 0),\n",
              " ('ˈfʂɘ̟stsɘ̟', 'ˈtoðu', 0),\n",
              " ('ˈfʂɘ̟stsɘ̟', \"'toðo\", 0),\n",
              " ('ˈfʂɘ̟stsɘ̟', 'tu', 0),\n",
              " ('ˈfʂɘ̟stsɘ̟', \"'tutto\", 0),\n",
              " ('ˈfʂɘ̟stsɘ̟', 'ˈɔlː', 0),\n",
              " ('ʋsi', 'ˈfʃɪxɲɪ', 1),\n",
              " ('ʋsi', 'ˈʋʲɪskɐs', 1),\n",
              " ('ʋsi', 'ˈad̥lɪr', 0),\n",
              " ('ʋsi', 'ˈàlːa', 0),\n",
              " ('ʋsi', 'ˈalə', 0),\n",
              " ('ʋsi', 'ɔ:l', 0),\n",
              " ('ʋsi', \"'ɑlə\", 0),\n",
              " ('ʋsi', \"'alə\", 0),\n",
              " ('ʋsi', 'tot', 0),\n",
              " ('ʋsi', 'ˈtoðu', 0),\n",
              " ('ʋsi', \"'toðo\", 0),\n",
              " ('ʋsi', 'tu', 0),\n",
              " ('ʋsi', \"'tutto\", 0),\n",
              " ('ʋsi', 'ˈɔlː', 0),\n",
              " ('ˈfʃɪxɲɪ', 'ˈʋʲɪskɐs', 1),\n",
              " ('ˈfʃɪxɲɪ', 'ˈad̥lɪr', 0),\n",
              " ('ˈfʃɪxɲɪ', 'ˈàlːa', 0),\n",
              " ('ˈfʃɪxɲɪ', 'ˈalə', 0),\n",
              " ('ˈfʃɪxɲɪ', 'ɔ:l', 0),\n",
              " ('ˈfʃɪxɲɪ', \"'ɑlə\", 0),\n",
              " ('ˈfʃɪxɲɪ', \"'alə\", 0),\n",
              " ('ˈfʃɪxɲɪ', 'tot', 0),\n",
              " ('ˈfʃɪxɲɪ', 'ˈtoðu', 0),\n",
              " ('ˈfʃɪxɲɪ', \"'toðo\", 0),\n",
              " ('ˈfʃɪxɲɪ', 'tu', 0),\n",
              " ('ˈfʃɪxɲɪ', \"'tutto\", 0),\n",
              " ('ˈfʃɪxɲɪ', 'ˈɔlː', 0),\n",
              " ('ˈʋʲɪskɐs', 'ˈad̥lɪr', 0),\n",
              " ('ˈʋʲɪskɐs', 'ˈàlːa', 0),\n",
              " ('ˈʋʲɪskɐs', 'ˈalə', 0),\n",
              " ('ˈʋʲɪskɐs', 'ɔ:l', 0),\n",
              " ('ˈʋʲɪskɐs', \"'ɑlə\", 0),\n",
              " ('ˈʋʲɪskɐs', \"'alə\", 0),\n",
              " ('ˈʋʲɪskɐs', 'tot', 0),\n",
              " ('ˈʋʲɪskɐs', 'ˈtoðu', 0),\n",
              " ('ˈʋʲɪskɐs', \"'toðo\", 0),\n",
              " ('ˈʋʲɪskɐs', 'tu', 0),\n",
              " ('ˈʋʲɪskɐs', \"'tutto\", 0),\n",
              " ('ˈʋʲɪskɐs', 'ˈɔlː', 0),\n",
              " ('ˈad̥lɪr', 'ˈàlːa', 1),\n",
              " ('ˈad̥lɪr', 'ˈalə', 1),\n",
              " ('ˈad̥lɪr', 'ɔ:l', 1),\n",
              " ('ˈad̥lɪr', \"'ɑlə\", 1),\n",
              " ('ˈad̥lɪr', \"'alə\", 1),\n",
              " ('ˈad̥lɪr', 'tot', 0),\n",
              " ('ˈad̥lɪr', 'ˈtoðu', 0),\n",
              " ('ˈad̥lɪr', \"'toðo\", 0),\n",
              " ('ˈad̥lɪr', 'tu', 0),\n",
              " ('ˈad̥lɪr', \"'tutto\", 0),\n",
              " ('ˈad̥lɪr', 'ˈɔlː', 0),\n",
              " ('ˈàlːa', 'ˈalə', 1),\n",
              " ('ˈàlːa', 'ɔ:l', 1),\n",
              " ('ˈàlːa', \"'ɑlə\", 1),\n",
              " ('ˈàlːa', \"'alə\", 1),\n",
              " ('ˈàlːa', 'tot', 0),\n",
              " ('ˈàlːa', 'ˈtoðu', 0),\n",
              " ('ˈàlːa', \"'toðo\", 0),\n",
              " ('ˈàlːa', 'tu', 0),\n",
              " ('ˈàlːa', \"'tutto\", 0),\n",
              " ('ˈàlːa', 'ˈɔlː', 0),\n",
              " ('ˈalə', 'ɔ:l', 1),\n",
              " ('ˈalə', \"'ɑlə\", 1),\n",
              " ('ˈalə', \"'alə\", 1),\n",
              " ('ˈalə', 'tot', 0),\n",
              " ('ˈalə', 'ˈtoðu', 0),\n",
              " ('ˈalə', \"'toðo\", 0),\n",
              " ('ˈalə', 'tu', 0),\n",
              " ('ˈalə', \"'tutto\", 0),\n",
              " ('ˈalə', 'ˈɔlː', 0),\n",
              " ('ɔ:l', \"'ɑlə\", 1),\n",
              " ('ɔ:l', \"'alə\", 1),\n",
              " ('ɔ:l', 'tot', 0),\n",
              " ('ɔ:l', 'ˈtoðu', 0),\n",
              " ('ɔ:l', \"'toðo\", 0),\n",
              " ('ɔ:l', 'tu', 0),\n",
              " ('ɔ:l', \"'tutto\", 0),\n",
              " ('ɔ:l', 'ˈɔlː', 0),\n",
              " (\"'ɑlə\", \"'alə\", 1),\n",
              " (\"'ɑlə\", 'tot', 0),\n",
              " (\"'ɑlə\", 'ˈtoðu', 0),\n",
              " (\"'ɑlə\", \"'toðo\", 0),\n",
              " (\"'ɑlə\", 'tu', 0),\n",
              " (\"'ɑlə\", \"'tutto\", 0),\n",
              " (\"'ɑlə\", 'ˈɔlː', 0),\n",
              " (\"'alə\", 'tot', 0),\n",
              " (\"'alə\", 'ˈtoðu', 0),\n",
              " (\"'alə\", \"'toðo\", 0),\n",
              " (\"'alə\", 'tu', 0),\n",
              " (\"'alə\", \"'tutto\", 0),\n",
              " (\"'alə\", 'ˈɔlː', 0),\n",
              " ('tot', 'ˈtoðu', 1),\n",
              " ('tot', \"'toðo\", 1),\n",
              " ('tot', 'tu', 1),\n",
              " ('tot', \"'tutto\", 1),\n",
              " ('tot', 'ˈɔlː', 0),\n",
              " ('ˈtoðu', \"'toðo\", 1),\n",
              " ('ˈtoðu', 'tu', 1),\n",
              " ('ˈtoðu', \"'tutto\", 1),\n",
              " ('ˈtoðu', 'ˈɔlː', 0),\n",
              " (\"'toðo\", 'tu', 1),\n",
              " (\"'toðo\", \"'tutto\", 1),\n",
              " (\"'toðo\", 'ˈɔlː', 0),\n",
              " ('tu', \"'tutto\", 1),\n",
              " ('tu', 'ˈɔlː', 0),\n",
              " (\"'tutto\", 'ˈɔlː', 0),\n",
              " ('ce̞', 'ɑːɹ', 0),\n",
              " ('ce̞', 'ebɔŋ', 0),\n",
              " ('ce̞', 'i', 0),\n",
              " ('ce̞', 'i', 0),\n",
              " ('ce̞', 'i', 0),\n",
              " ('ce̞', 'i', 0),\n",
              " ('ce̞', 'a', 0),\n",
              " ('ce̞', 'ɔːɣ', 0),\n",
              " ('ce̞', 'ɔ(kː)', 0),\n",
              " ('ce̞', 'ɒw, ʌ', 0),\n",
              " ('ce̞', 'ænd', 0),\n",
              " ('ce̞', 'ɛn', 0),\n",
              " ('ce̞', 'ʊnt', 0),\n",
              " ('ce̞', 'i', 0),\n",
              " ('ce̞', 'i', 0),\n",
              " ('ce̞', 'i', 0),\n",
              " ('ce̞', 'e', 0),\n",
              " ('ce̞', 'e, ed', 0),\n",
              " ('ce̞', 'a, aɡ', 0),\n",
              " ('ce̞', 'a:', 0),\n",
              " ('ce̞', 'ˈaɡəs', 0),\n",
              " ('ɑːɹ', 'ebɔŋ', 0),\n",
              " ('ɑːɹ', 'i', 0),\n",
              " ('ɑːɹ', 'i', 0),\n",
              " ('ɑːɹ', 'i', 0),\n",
              " ('ɑːɹ', 'i', 0),\n",
              " ('ɑːɹ', 'a', 0),\n",
              " ('ɑːɹ', 'ɔːɣ', 0),\n",
              " ('ɑːɹ', 'ɔ(kː)', 0),\n",
              " ('ɑːɹ', 'ɒw, ʌ', 0),\n",
              " ('ɑːɹ', 'ænd', 0),\n",
              " ('ɑːɹ', 'ɛn', 0),\n",
              " ('ɑːɹ', 'ʊnt', 0),\n",
              " ('ɑːɹ', 'i', 0),\n",
              " ('ɑːɹ', 'i', 0),\n",
              " ('ɑːɹ', 'i', 0),\n",
              " ('ɑːɹ', 'e', 0),\n",
              " ('ɑːɹ', 'e, ed', 0),\n",
              " ('ɑːɹ', 'a, aɡ', 0),\n",
              " ('ɑːɹ', 'a:', 0),\n",
              " ('ɑːɹ', 'ˈaɡəs', 0),\n",
              " ('ebɔŋ', 'i', 0),\n",
              " ('ebɔŋ', 'i', 0),\n",
              " ('ebɔŋ', 'i', 0),\n",
              " ('ebɔŋ', 'i', 0),\n",
              " ('ebɔŋ', 'a', 0),\n",
              " ('ebɔŋ', 'ɔːɣ', 0),\n",
              " ('ebɔŋ', 'ɔ(kː)', 0),\n",
              " ('ebɔŋ', 'ɒw, ʌ', 0),\n",
              " ('ebɔŋ', 'ænd', 0),\n",
              " ('ebɔŋ', 'ɛn', 0),\n",
              " ('ebɔŋ', 'ʊnt', 0),\n",
              " ('ebɔŋ', 'i', 0),\n",
              " ('ebɔŋ', 'i', 0),\n",
              " ('ebɔŋ', 'i', 0),\n",
              " ('ebɔŋ', 'e', 0),\n",
              " ('ebɔŋ', 'e, ed', 0),\n",
              " ('ebɔŋ', 'a, aɡ', 0),\n",
              " ('ebɔŋ', 'a:', 0),\n",
              " ('ebɔŋ', 'ˈaɡəs', 0),\n",
              " ('i', 'i', 1),\n",
              " ('i', 'i', 1),\n",
              " ('i', 'i', 1),\n",
              " ('i', 'a', 0),\n",
              " ('i', 'ɔːɣ', 0),\n",
              " ('i', 'ɔ(kː)', 0),\n",
              " ('i', 'ɒw, ʌ', 0),\n",
              " ('i', 'ænd', 0),\n",
              " ('i', 'ɛn', 0),\n",
              " ('i', 'ʊnt', 0),\n",
              " ('i', 'i', 0),\n",
              " ('i', 'i', 0),\n",
              " ('i', 'i', 0),\n",
              " ('i', 'e', 0),\n",
              " ('i', 'e, ed', 0),\n",
              " ('i', 'a, aɡ', 0),\n",
              " ('i', 'a:', 0),\n",
              " ('i', 'ˈaɡəs', 0),\n",
              " ('i', 'i', 1),\n",
              " ('i', 'i', 1),\n",
              " ('i', 'a', 0),\n",
              " ('i', 'ɔːɣ', 0),\n",
              " ('i', 'ɔ(kː)', 0),\n",
              " ('i', 'ɒw, ʌ', 0),\n",
              " ('i', 'ænd', 0),\n",
              " ('i', 'ɛn', 0),\n",
              " ('i', 'ʊnt', 0),\n",
              " ('i', 'i', 0),\n",
              " ('i', 'i', 0),\n",
              " ('i', 'i', 0),\n",
              " ('i', 'e', 0),\n",
              " ('i', 'e, ed', 0),\n",
              " ('i', 'a, aɡ', 0),\n",
              " ('i', 'a:', 0),\n",
              " ('i', 'ˈaɡəs', 0),\n",
              " ('i', 'i', 1),\n",
              " ('i', 'a', 0),\n",
              " ('i', 'ɔːɣ', 0),\n",
              " ('i', 'ɔ(kː)', 0),\n",
              " ('i', 'ɒw, ʌ', 0),\n",
              " ('i', 'ænd', 0),\n",
              " ('i', 'ɛn', 0),\n",
              " ('i', 'ʊnt', 0),\n",
              " ('i', 'i', 0),\n",
              " ('i', 'i', 0),\n",
              " ('i', 'i', 0),\n",
              " ('i', 'e', 0),\n",
              " ('i', 'e, ed', 0),\n",
              " ('i', 'a, aɡ', 0),\n",
              " ('i', 'a:', 0),\n",
              " ('i', 'ˈaɡəs', 0),\n",
              " ('i', 'a', 0),\n",
              " ('i', 'ɔːɣ', 0),\n",
              " ('i', 'ɔ(kː)', 0),\n",
              " ('i', 'ɒw, ʌ', 0),\n",
              " ('i', 'ænd', 0),\n",
              " ('i', 'ɛn', 0),\n",
              " ('i', 'ʊnt', 0),\n",
              " ('i', 'i', 0),\n",
              " ('i', 'i', 0),\n",
              " ('i', 'i', 0),\n",
              " ('i', 'e', 0),\n",
              " ('i', 'e, ed', 0),\n",
              " ('i', 'a, aɡ', 0),\n",
              " ('i', 'a:', 0),\n",
              " ('i', 'ˈaɡəs', 0),\n",
              " ('a', 'ɔːɣ', 0),\n",
              " ('a', 'ɔ(kː)', 0),\n",
              " ('a', 'ɒw, ʌ', 0),\n",
              " ('a', 'ænd', 0),\n",
              " ('a', 'ɛn', 0),\n",
              " ('a', 'ʊnt', 0),\n",
              " ('a', 'i', 0),\n",
              " ('a', 'i', 0),\n",
              " ('a', 'i', 0),\n",
              " ('a', 'e', 0),\n",
              " ('a', 'e, ed', 0),\n",
              " ('a', 'a, aɡ', 0),\n",
              " ('a', 'a:', 0),\n",
              " ('a', 'ˈaɡəs', 0),\n",
              " ('ɔːɣ', 'ɔ(kː)', 1),\n",
              " ('ɔːɣ', 'ɒw, ʌ', 1),\n",
              " ('ɔːɣ', 'ænd', 0),\n",
              " ('ɔːɣ', 'ɛn', 0),\n",
              " ('ɔːɣ', 'ʊnt', 0),\n",
              " ('ɔːɣ', 'i', 0),\n",
              " ('ɔːɣ', 'i', 0),\n",
              " ('ɔːɣ', 'i', 0),\n",
              " ('ɔːɣ', 'e', 0),\n",
              " ('ɔːɣ', 'e, ed', 0),\n",
              " ('ɔːɣ', 'a, aɡ', 0),\n",
              " ('ɔːɣ', 'a:', 0),\n",
              " ('ɔːɣ', 'ˈaɡəs', 0),\n",
              " ('ɔ(kː)', 'ɒw, ʌ', 1),\n",
              " ('ɔ(kː)', 'ænd', 0),\n",
              " ('ɔ(kː)', 'ɛn', 0),\n",
              " ('ɔ(kː)', 'ʊnt', 0),\n",
              " ('ɔ(kː)', 'i', 0),\n",
              " ('ɔ(kː)', 'i', 0),\n",
              " ('ɔ(kː)', 'i', 0),\n",
              " ('ɔ(kː)', 'e', 0),\n",
              " ('ɔ(kː)', 'e, ed', 0),\n",
              " ('ɔ(kː)', 'a, aɡ', 0),\n",
              " ('ɔ(kː)', 'a:', 0),\n",
              " ('ɔ(kː)', 'ˈaɡəs', 0),\n",
              " ('ɒw, ʌ', 'ænd', 0),\n",
              " ('ɒw, ʌ', 'ɛn', 0),\n",
              " ('ɒw, ʌ', 'ʊnt', 0),\n",
              " ('ɒw, ʌ', 'i', 0),\n",
              " ('ɒw, ʌ', 'i', 0),\n",
              " ('ɒw, ʌ', 'i', 0),\n",
              " ('ɒw, ʌ', 'e', 0),\n",
              " ('ɒw, ʌ', 'e, ed', 0),\n",
              " ('ɒw, ʌ', 'a, aɡ', 0),\n",
              " ('ɒw, ʌ', 'a:', 0),\n",
              " ('ɒw, ʌ', 'ˈaɡəs', 0),\n",
              " ('ænd', 'ɛn', 1),\n",
              " ('ænd', 'ʊnt', 1),\n",
              " ('ænd', 'i', 0),\n",
              " ('ænd', 'i', 0),\n",
              " ('ænd', 'i', 0),\n",
              " ('ænd', 'e', 0),\n",
              " ('ænd', 'e, ed', 0),\n",
              " ('ænd', 'a, aɡ', 0),\n",
              " ('ænd', 'a:', 0),\n",
              " ('ænd', 'ˈaɡəs', 0),\n",
              " ('ɛn', 'ʊnt', 1),\n",
              " ('ɛn', 'i', 0),\n",
              " ('ɛn', 'i', 0),\n",
              " ('ɛn', 'i', 0),\n",
              " ('ɛn', 'e', 0),\n",
              " ('ɛn', 'e, ed', 0),\n",
              " ('ɛn', 'a, aɡ', 0),\n",
              " ('ɛn', 'a:', 0),\n",
              " ('ɛn', 'ˈaɡəs', 0),\n",
              " ('ʊnt', 'i', 0),\n",
              " ('ʊnt', 'i', 0),\n",
              " ('ʊnt', 'i', 0),\n",
              " ('ʊnt', 'e', 0),\n",
              " ('ʊnt', 'e, ed', 0),\n",
              " ('ʊnt', 'a, aɡ', 0),\n",
              " ('ʊnt', 'a:', 0),\n",
              " ('ʊnt', 'ˈaɡəs', 0),\n",
              " ('i', 'i', 1),\n",
              " ('i', 'i', 1),\n",
              " ('i', 'e', 1),\n",
              " ('i', 'e, ed', 1),\n",
              " ('i', 'a, aɡ', 0),\n",
              " ('i', 'a:', 0),\n",
              " ('i', 'ˈaɡəs', 0),\n",
              " ('i', 'i', 1),\n",
              " ('i', 'e', 1),\n",
              " ('i', 'e, ed', 1),\n",
              " ('i', 'a, aɡ', 0),\n",
              " ('i', 'a:', 0),\n",
              " ('i', 'ˈaɡəs', 0),\n",
              " ('i', 'e', 1),\n",
              " ('i', 'e, ed', 1),\n",
              " ('i', 'a, aɡ', 0),\n",
              " ('i', 'a:', 0),\n",
              " ('i', 'ˈaɡəs', 0),\n",
              " ('e', 'e, ed', 1),\n",
              " ('e', 'a, aɡ', 0),\n",
              " ('e', 'a:', 0),\n",
              " ('e', 'ˈaɡəs', 0),\n",
              " ('e, ed', 'a, aɡ', 0),\n",
              " ('e, ed', 'a:', 0),\n",
              " ('e, ed', 'ˈaɡəs', 0),\n",
              " ('a, aɡ', 'a:', 1),\n",
              " ('a, aɡ', 'ˈaɡəs', 1),\n",
              " ('a:', 'ˈaɡəs', 1),\n",
              " ('ˈzo̞ˌo̞', 'ˈdʒanʋər', 0),\n",
              " ('ˈzo̞ˌo̞', 'ʒiˈvɔtnu', 1),\n",
              " ('ˈzo̞ˌo̞', \"ʐɨ'vɔtnɔjɛ\", 1),\n",
              " ('ˈzo̞ˌo̞', 'ˈzvjɛʐɛ(ɰ̃)', 0),\n",
              " ('ˈzo̞ˌo̞', 'tʋaˈrɪna', 0),\n",
              " ('ˈzo̞ˌo̞', 'ˈzviːr̝ɛ', 0),\n",
              " ('ˈzo̞ˌo̞', 'd̥iːr', 0),\n",
              " ('ˈzo̞ˌo̞', 'jʉːr', 0),\n",
              " ('ˈzo̞ˌo̞', 'ˈd̥yɐ̯ˀ', 0),\n",
              " ('ˈzo̞ˌo̞', \"'ænɪməl\", 0),\n",
              " ('ˈzo̞ˌo̞', 'dir', 0),\n",
              " ('ˈzo̞ˌo̞', 'ti:ɐ̯', 0),\n",
              " ('ˈzo̞ˌo̞', 'əni’mal', 0),\n",
              " ('ˈzo̞ˌo̞', 'ɐniˈmaɫ', 0),\n",
              " ('ˈzo̞ˌo̞', \"ani'mal\", 0),\n",
              " ('ˈzo̞ˌo̞', 'animal', 0),\n",
              " ('ˈzo̞ˌo̞', \"ani'male\", 0),\n",
              " ('ˈzo̞ˌo̞', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('ˈzo̞ˌo̞', 'ãˈneːval', 0),\n",
              " ('ˈdʒanʋər', 'ʒiˈvɔtnu', 0),\n",
              " ('ˈdʒanʋər', \"ʐɨ'vɔtnɔjɛ\", 0),\n",
              " ('ˈdʒanʋər', 'ˈzvjɛʐɛ(ɰ̃)', 0),\n",
              " ('ˈdʒanʋər', 'tʋaˈrɪna', 0),\n",
              " ('ˈdʒanʋər', 'ˈzviːr̝ɛ', 0),\n",
              " ('ˈdʒanʋər', 'd̥iːr', 0),\n",
              " ('ˈdʒanʋər', 'jʉːr', 0),\n",
              " ('ˈdʒanʋər', 'ˈd̥yɐ̯ˀ', 0),\n",
              " ('ˈdʒanʋər', \"'ænɪməl\", 0),\n",
              " ('ˈdʒanʋər', 'dir', 0),\n",
              " ('ˈdʒanʋər', 'ti:ɐ̯', 0),\n",
              " ('ˈdʒanʋər', 'əni’mal', 0),\n",
              " ('ˈdʒanʋər', 'ɐniˈmaɫ', 0),\n",
              " ('ˈdʒanʋər', \"ani'mal\", 0),\n",
              " ('ˈdʒanʋər', 'animal', 0),\n",
              " ('ˈdʒanʋər', \"ani'male\", 0),\n",
              " ('ˈdʒanʋər', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('ˈdʒanʋər', 'ãˈneːval', 0),\n",
              " ('ʒiˈvɔtnu', \"ʐɨ'vɔtnɔjɛ\", 1),\n",
              " ('ʒiˈvɔtnu', 'ˈzvjɛʐɛ(ɰ̃)', 0),\n",
              " ('ʒiˈvɔtnu', 'tʋaˈrɪna', 0),\n",
              " ('ʒiˈvɔtnu', 'ˈzviːr̝ɛ', 0),\n",
              " ('ʒiˈvɔtnu', 'd̥iːr', 0),\n",
              " ('ʒiˈvɔtnu', 'jʉːr', 0),\n",
              " ('ʒiˈvɔtnu', 'ˈd̥yɐ̯ˀ', 0),\n",
              " ('ʒiˈvɔtnu', \"'ænɪməl\", 0),\n",
              " ('ʒiˈvɔtnu', 'dir', 0),\n",
              " ('ʒiˈvɔtnu', 'ti:ɐ̯', 0),\n",
              " ('ʒiˈvɔtnu', 'əni’mal', 0),\n",
              " ('ʒiˈvɔtnu', 'ɐniˈmaɫ', 0),\n",
              " ('ʒiˈvɔtnu', \"ani'mal\", 0),\n",
              " ('ʒiˈvɔtnu', 'animal', 0),\n",
              " ('ʒiˈvɔtnu', \"ani'male\", 0),\n",
              " ('ʒiˈvɔtnu', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('ʒiˈvɔtnu', 'ãˈneːval', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'ˈzvjɛʐɛ(ɰ̃)', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'tʋaˈrɪna', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'ˈzviːr̝ɛ', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'd̥iːr', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'jʉːr', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'ˈd̥yɐ̯ˀ', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", \"'ænɪməl\", 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'dir', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'ti:ɐ̯', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'əni’mal', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'ɐniˈmaɫ', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", \"ani'mal\", 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'animal', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", \"ani'male\", 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " (\"ʐɨ'vɔtnɔjɛ\", 'ãˈneːval', 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', 'tʋaˈrɪna', 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', 'ˈzviːr̝ɛ', 1),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', 'd̥iːr', 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', 'jʉːr', 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', 'ˈd̥yɐ̯ˀ', 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', \"'ænɪməl\", 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', 'dir', 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', 'ti:ɐ̯', 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', 'əni’mal', 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', 'ɐniˈmaɫ', 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', \"ani'mal\", 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', 'animal', 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', \"ani'male\", 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('ˈzvjɛʐɛ(ɰ̃)', 'ãˈneːval', 0),\n",
              " ('tʋaˈrɪna', 'ˈzviːr̝ɛ', 0),\n",
              " ('tʋaˈrɪna', 'd̥iːr', 0),\n",
              " ('tʋaˈrɪna', 'jʉːr', 0),\n",
              " ('tʋaˈrɪna', 'ˈd̥yɐ̯ˀ', 0),\n",
              " ('tʋaˈrɪna', \"'ænɪməl\", 0),\n",
              " ('tʋaˈrɪna', 'dir', 0),\n",
              " ('tʋaˈrɪna', 'ti:ɐ̯', 0),\n",
              " ('tʋaˈrɪna', 'əni’mal', 0),\n",
              " ('tʋaˈrɪna', 'ɐniˈmaɫ', 0),\n",
              " ('tʋaˈrɪna', \"ani'mal\", 0),\n",
              " ('tʋaˈrɪna', 'animal', 0),\n",
              " ('tʋaˈrɪna', \"ani'male\", 0),\n",
              " ('tʋaˈrɪna', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('tʋaˈrɪna', 'ãˈneːval', 0),\n",
              " ('ˈzviːr̝ɛ', 'd̥iːr', 0),\n",
              " ('ˈzviːr̝ɛ', 'jʉːr', 0),\n",
              " ('ˈzviːr̝ɛ', 'ˈd̥yɐ̯ˀ', 0),\n",
              " ('ˈzviːr̝ɛ', \"'ænɪməl\", 0),\n",
              " ('ˈzviːr̝ɛ', 'dir', 0),\n",
              " ('ˈzviːr̝ɛ', 'ti:ɐ̯', 0),\n",
              " ('ˈzviːr̝ɛ', 'əni’mal', 0),\n",
              " ('ˈzviːr̝ɛ', 'ɐniˈmaɫ', 0),\n",
              " ('ˈzviːr̝ɛ', \"ani'mal\", 0),\n",
              " ('ˈzviːr̝ɛ', 'animal', 0),\n",
              " ('ˈzviːr̝ɛ', \"ani'male\", 0),\n",
              " ('ˈzviːr̝ɛ', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('ˈzviːr̝ɛ', 'ãˈneːval', 0),\n",
              " ('d̥iːr', 'jʉːr', 1),\n",
              " ('d̥iːr', 'ˈd̥yɐ̯ˀ', 1),\n",
              " ('d̥iːr', \"'ænɪməl\", 0),\n",
              " ('d̥iːr', 'dir', 1),\n",
              " ('d̥iːr', 'ti:ɐ̯', 1),\n",
              " ('d̥iːr', 'əni’mal', 0),\n",
              " ('d̥iːr', 'ɐniˈmaɫ', 0),\n",
              " ('d̥iːr', \"ani'mal\", 0),\n",
              " ('d̥iːr', 'animal', 0),\n",
              " ('d̥iːr', \"ani'male\", 0),\n",
              " ('d̥iːr', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('d̥iːr', 'ãˈneːval', 0),\n",
              " ('jʉːr', 'ˈd̥yɐ̯ˀ', 1),\n",
              " ('jʉːr', \"'ænɪməl\", 0),\n",
              " ('jʉːr', 'dir', 1),\n",
              " ('jʉːr', 'ti:ɐ̯', 1),\n",
              " ('jʉːr', 'əni’mal', 0),\n",
              " ('jʉːr', 'ɐniˈmaɫ', 0),\n",
              " ('jʉːr', \"ani'mal\", 0),\n",
              " ('jʉːr', 'animal', 0),\n",
              " ('jʉːr', \"ani'male\", 0),\n",
              " ('jʉːr', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('jʉːr', 'ãˈneːval', 0),\n",
              " ('ˈd̥yɐ̯ˀ', \"'ænɪməl\", 0),\n",
              " ('ˈd̥yɐ̯ˀ', 'dir', 1),\n",
              " ('ˈd̥yɐ̯ˀ', 'ti:ɐ̯', 1),\n",
              " ('ˈd̥yɐ̯ˀ', 'əni’mal', 0),\n",
              " ('ˈd̥yɐ̯ˀ', 'ɐniˈmaɫ', 0),\n",
              " ('ˈd̥yɐ̯ˀ', \"ani'mal\", 0),\n",
              " ('ˈd̥yɐ̯ˀ', 'animal', 0),\n",
              " ('ˈd̥yɐ̯ˀ', \"ani'male\", 0),\n",
              " ('ˈd̥yɐ̯ˀ', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('ˈd̥yɐ̯ˀ', 'ãˈneːval', 0),\n",
              " (\"'ænɪməl\", 'dir', 0),\n",
              " (\"'ænɪməl\", 'ti:ɐ̯', 0),\n",
              " (\"'ænɪməl\", 'əni’mal', 1),\n",
              " (\"'ænɪməl\", 'ɐniˈmaɫ', 1),\n",
              " (\"'ænɪməl\", \"ani'mal\", 1),\n",
              " (\"'ænɪməl\", 'animal', 1),\n",
              " (\"'ænɪməl\", \"ani'male\", 1),\n",
              " (\"'ænɪməl\", 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " (\"'ænɪməl\", 'ãˈneːval', 0),\n",
              " ('dir', 'ti:ɐ̯', 1),\n",
              " ('dir', 'əni’mal', 0),\n",
              " ('dir', 'ɐniˈmaɫ', 0),\n",
              " ('dir', \"ani'mal\", 0),\n",
              " ('dir', 'animal', 0),\n",
              " ('dir', \"ani'male\", 0),\n",
              " ('dir', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('dir', 'ãˈneːval', 0),\n",
              " ('ti:ɐ̯', 'əni’mal', 0),\n",
              " ('ti:ɐ̯', 'ɐniˈmaɫ', 0),\n",
              " ('ti:ɐ̯', \"ani'mal\", 0),\n",
              " ('ti:ɐ̯', 'animal', 0),\n",
              " ('ti:ɐ̯', \"ani'male\", 0),\n",
              " ('ti:ɐ̯', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('ti:ɐ̯', 'ãˈneːval', 0),\n",
              " ('əni’mal', 'ɐniˈmaɫ', 1),\n",
              " ('əni’mal', \"ani'mal\", 1),\n",
              " ('əni’mal', 'animal', 1),\n",
              " ('əni’mal', \"ani'male\", 1),\n",
              " ('əni’mal', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('əni’mal', 'ãˈneːval', 0),\n",
              " ('ɐniˈmaɫ', \"ani'mal\", 1),\n",
              " ('ɐniˈmaɫ', 'animal', 1),\n",
              " ('ɐniˈmaɫ', \"ani'male\", 1),\n",
              " ('ɐniˈmaɫ', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('ɐniˈmaɫ', 'ãˈneːval', 0),\n",
              " (\"ani'mal\", 'animal', 1),\n",
              " (\"ani'mal\", \"ani'male\", 1),\n",
              " (\"ani'mal\", 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " (\"ani'mal\", 'ãˈneːval', 0),\n",
              " ('animal', \"ani'male\", 1),\n",
              " ('animal', 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " ('animal', 'ãˈneːval', 0),\n",
              " (\"ani'male\", 'ˈlwẽːn, ˈlɔ̃ːn', 0),\n",
              " (\"ani'male\", 'ãˈneːval', 0),\n",
              " ('ˈlwẽːn, ˈlɔ̃ːn', 'ãˈneːval', 0),\n",
              " ('mirˈmiŋɟi', 'ˈmravka', 0),\n",
              " ('mirˈmiŋɟi', 'muraˈvʲɛj', 0),\n",
              " ('mirˈmiŋɟi', 'ˈmruvka', 0),\n",
              " ('mirˈmiŋɟi', 'muˈraxa', 0),\n",
              " ('mirˈmiŋɟi', 'ˈmravɛnɛts', 0),\n",
              " ('ˈmravka', 'muraˈvʲɛj', 1),\n",
              " ('ˈmravka', 'ˈmruvka', 1),\n",
              " ('ˈmravka', 'muˈraxa', 1),\n",
              " ('ˈmravka', 'ˈmravɛnɛts', 1),\n",
              " ('muraˈvʲɛj', 'ˈmruvka', 1),\n",
              " ('muraˈvʲɛj', 'muˈraxa', 1),\n",
              " ('muraˈvʲɛj', 'ˈmravɛnɛts', 1),\n",
              " ('ˈmruvka', 'muˈraxa', 1),\n",
              " ('ˈmruvka', 'ˈmravɛnɛts', 1),\n",
              " ('muˈraxa', 'ˈmravɛnɛts', 1),\n",
              " ('ˈte̞fra', 'ˈstaxti', 0),\n",
              " ('ˈte̞fra', 'rakʰ', 0),\n",
              " ('ˈte̞fra', 'ˈpɛpɘɫ', 0),\n",
              " ('ˈte̞fra', 'zɔˈɫa', 0),\n",
              " ('ˈte̞fra', 'ˈpɔpjuw', 0),\n",
              " ('ˈte̞fra', 'ˈpɔpiɫ', 0),\n",
              " ('ˈte̞fra', 'ˈpopɛl', 0),\n",
              " ('ˈte̞fra', 'ˈaska', 0),\n",
              " ('ˈte̞fra', 'stɔft', 0),\n",
              " ('ˈte̞fra', 'ˈàska', 0),\n",
              " ('ˈte̞fra', 'ˈasg̥ʰə', 0),\n",
              " ('ˈte̞fra', 'æʃɪz', 0),\n",
              " ('ˈte̞fra', 'ɑs', 0),\n",
              " ('ˈte̞fra', \"'aʃə\", 0),\n",
              " ('ˈte̞fra', \"'sɛndrə\", 0),\n",
              " ('ˈte̞fra', 'ˈsĩzɐʃ', 0),\n",
              " ('ˈte̞fra', \"θe'niθas\", 0),\n",
              " ('ˈte̞fra', 'sɑ̃dʀ', 0),\n",
              " ('ˈte̞fra', \"'tʃenere\", 0),\n",
              " ('ˈte̞fra', 'ˈlyːdy', 0),\n",
              " ('ˈstaxti', 'rakʰ', 0),\n",
              " ('ˈstaxti', 'ˈpɛpɘɫ', 0),\n",
              " ('ˈstaxti', 'zɔˈɫa', 0),\n",
              " ('ˈstaxti', 'ˈpɔpjuw', 0),\n",
              " ('ˈstaxti', 'ˈpɔpiɫ', 0),\n",
              " ('ˈstaxti', 'ˈpopɛl', 0),\n",
              " ('ˈstaxti', 'ˈaska', 0),\n",
              " ('ˈstaxti', 'stɔft', 1),\n",
              " ('ˈstaxti', 'ˈàska', 0),\n",
              " ('ˈstaxti', 'ˈasg̥ʰə', 0),\n",
              " ('ˈstaxti', 'æʃɪz', 0),\n",
              " ('ˈstaxti', 'ɑs', 0),\n",
              " ('ˈstaxti', \"'aʃə\", 0),\n",
              " ('ˈstaxti', \"'sɛndrə\", 0),\n",
              " ('ˈstaxti', 'ˈsĩzɐʃ', 0),\n",
              " ('ˈstaxti', \"θe'niθas\", 0),\n",
              " ('ˈstaxti', 'sɑ̃dʀ', 0),\n",
              " ('ˈstaxti', \"'tʃenere\", 0),\n",
              " ('ˈstaxti', 'ˈlyːdy', 0),\n",
              " ('rakʰ', 'ˈpɛpɘɫ', 0),\n",
              " ('rakʰ', 'zɔˈɫa', 0),\n",
              " ('rakʰ', 'ˈpɔpjuw', 0),\n",
              " ('rakʰ', 'ˈpɔpiɫ', 0),\n",
              " ('rakʰ', 'ˈpopɛl', 0),\n",
              " ('rakʰ', 'ˈaska', 0),\n",
              " ('rakʰ', 'stɔft', 0),\n",
              " ('rakʰ', 'ˈàska', 0),\n",
              " ('rakʰ', 'ˈasg̥ʰə', 0),\n",
              " ('rakʰ', 'æʃɪz', 0),\n",
              " ('rakʰ', 'ɑs', 0),\n",
              " ('rakʰ', \"'aʃə\", 0),\n",
              " ('rakʰ', \"'sɛndrə\", 0),\n",
              " ('rakʰ', 'ˈsĩzɐʃ', 0),\n",
              " ('rakʰ', \"θe'niθas\", 0),\n",
              " ('rakʰ', 'sɑ̃dʀ', 0),\n",
              " ('rakʰ', \"'tʃenere\", 0),\n",
              " ('rakʰ', 'ˈlyːdy', 0),\n",
              " ('ˈpɛpɘɫ', 'zɔˈɫa', 0),\n",
              " ('ˈpɛpɘɫ', 'ˈpɔpjuw', 1),\n",
              " ('ˈpɛpɘɫ', 'ˈpɔpiɫ', 1),\n",
              " ('ˈpɛpɘɫ', 'ˈpopɛl', 1),\n",
              " ('ˈpɛpɘɫ', 'ˈaska', 0),\n",
              " ('ˈpɛpɘɫ', 'stɔft', 0),\n",
              " ('ˈpɛpɘɫ', 'ˈàska', 0),\n",
              " ('ˈpɛpɘɫ', 'ˈasg̥ʰə', 0),\n",
              " ('ˈpɛpɘɫ', 'æʃɪz', 0),\n",
              " ('ˈpɛpɘɫ', 'ɑs', 0),\n",
              " ('ˈpɛpɘɫ', \"'aʃə\", 0),\n",
              " ('ˈpɛpɘɫ', \"'sɛndrə\", 0),\n",
              " ('ˈpɛpɘɫ', 'ˈsĩzɐʃ', 0),\n",
              " ('ˈpɛpɘɫ', \"θe'niθas\", 0),\n",
              " ('ˈpɛpɘɫ', 'sɑ̃dʀ', 0),\n",
              " ('ˈpɛpɘɫ', \"'tʃenere\", 0),\n",
              " ('ˈpɛpɘɫ', 'ˈlyːdy', 0),\n",
              " ('zɔˈɫa', 'ˈpɔpjuw', 0),\n",
              " ('zɔˈɫa', 'ˈpɔpiɫ', 0),\n",
              " ('zɔˈɫa', 'ˈpopɛl', 0),\n",
              " ('zɔˈɫa', 'ˈaska', 0),\n",
              " ('zɔˈɫa', 'stɔft', 0),\n",
              " ('zɔˈɫa', 'ˈàska', 0),\n",
              " ('zɔˈɫa', 'ˈasg̥ʰə', 0),\n",
              " ('zɔˈɫa', 'æʃɪz', 0),\n",
              " ('zɔˈɫa', 'ɑs', 0),\n",
              " ('zɔˈɫa', \"'aʃə\", 0),\n",
              " ('zɔˈɫa', \"'sɛndrə\", 0),\n",
              " ('zɔˈɫa', 'ˈsĩzɐʃ', 0),\n",
              " ('zɔˈɫa', \"θe'niθas\", 0),\n",
              " ('zɔˈɫa', 'sɑ̃dʀ', 0),\n",
              " ('zɔˈɫa', \"'tʃenere\", 0),\n",
              " ('zɔˈɫa', 'ˈlyːdy', 0),\n",
              " ('ˈpɔpjuw', 'ˈpɔpiɫ', 1),\n",
              " ('ˈpɔpjuw', 'ˈpopɛl', 1),\n",
              " ('ˈpɔpjuw', 'ˈaska', 0),\n",
              " ('ˈpɔpjuw', 'stɔft', 0),\n",
              " ('ˈpɔpjuw', 'ˈàska', 0),\n",
              " ('ˈpɔpjuw', 'ˈasg̥ʰə', 0),\n",
              " ('ˈpɔpjuw', 'æʃɪz', 0),\n",
              " ('ˈpɔpjuw', 'ɑs', 0),\n",
              " ...]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word1</th>\n",
              "      <th>Word2</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>e̞ˈɣo̞</td>\n",
              "      <td>'ɑmi:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e̞ˈɣo̞</td>\n",
              "      <td>mɛ̃</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e̞ˈɣo̞</td>\n",
              "      <td>as</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>e̞ˈɣo̞</td>\n",
              "      <td>ja</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e̞ˈɣo̞</td>\n",
              "      <td>ja</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47269</th>\n",
              "      <td>voj</td>\n",
              "      <td>xwi</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47270</th>\n",
              "      <td>voj</td>\n",
              "      <td>ʃivʲ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47271</th>\n",
              "      <td>ˈxwi, ˈhwi</td>\n",
              "      <td>xwi</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47272</th>\n",
              "      <td>ˈxwi, ˈhwi</td>\n",
              "      <td>ʃivʲ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47273</th>\n",
              "      <td>xwi</td>\n",
              "      <td>ʃivʲ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47274 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Word1  Word2  Label\n",
              "0          e̞ˈɣo̞  'ɑmi:      1\n",
              "1          e̞ˈɣo̞    mɛ̃      1\n",
              "2          e̞ˈɣo̞     as      1\n",
              "3          e̞ˈɣo̞     ja      1\n",
              "4          e̞ˈɣo̞     ja      1\n",
              "...           ...    ...    ...\n",
              "47269         voj    xwi      1\n",
              "47270         voj   ʃivʲ      1\n",
              "47271  ˈxwi, ˈhwi    xwi      1\n",
              "47272  ˈxwi, ˈhwi   ʃivʲ      1\n",
              "47273         xwi   ʃivʲ      1\n",
              "\n",
              "[47274 rows x 3 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pairs_df = pd.DataFrame(pairs, columns=['Word1', 'Word2', 'Label'])\n",
        "pairs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ADOIbTNAlzdh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import LeaveOneOut, KFold, StratifiedKFold\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# Prepare data\n",
        "all_words = [w for pair in pairs for w in pair[:2]]\n",
        "all_answers = [w for pair in pairs for w in pair[2:]]\n",
        "unique_characters = sorted(set(\"\".join(all_words)))\n",
        "maxlen = max(len(w) for w in all_words)\n",
        "\n",
        "def cv_test_model(model_maker):\n",
        "\n",
        "    # Initialize Leave-One-Out cross-validator\n",
        "    loo = StratifiedKFold(n_splits = 10) #LeaveOneOut()\n",
        "\n",
        "    # Store results for each fold\n",
        "    fold_accuracies = []\n",
        "    all_predictions = []\n",
        "    all_true_labels = []\n",
        "\n",
        "    for fold, (train_idx, test_idx) in enumerate(tqdm(loo.split(pairs_df.iloc[:, :2], pairs_df.iloc[:, 2:]), total=loo.get_n_splits(), desc=\"LOO-CV Progress\")):\n",
        "        # Split data\n",
        "        train_data = [pairs[i] for i in train_idx]\n",
        "        test_data = [pairs[i] for i in test_idx]\n",
        "        \n",
        "        # Create model for this fold\n",
        "        model = model_maker()\n",
        "        criterion = nn.BCELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        \n",
        "        # Create datasets and dataloaders\n",
        "        train_dataset = SimpleCognateDataset(train_data, unique_characters, maxlen)\n",
        "        test_dataset = SimpleCognateDataset(test_data, unique_characters, maxlen)\n",
        "        \n",
        "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, \n",
        "                                generator=torch.Generator(device='cuda'))\n",
        "        test_loader = DataLoader(test_dataset, batch_size=1, \n",
        "                                generator=torch.Generator(device='cuda'))\n",
        "        \n",
        "        # Train model (fewer epochs since we're doing many folds)\n",
        "        model.train()\n",
        "        for epoch in range(5):  # Reduced epochs for LOO-CV\n",
        "            total_loss = 0\n",
        "            for word1, word2, label in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                output = model(word1, word2).squeeze()\n",
        "                #print(output.get_device(), label.get_device())\n",
        "                loss = criterion(output, label)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "        \n",
        "        # Test on the single held-out sample\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for word1, word2, label in test_loader:\n",
        "                output = model(word1, word2).squeeze()\n",
        "                predicted = (output > 0.5).int()\n",
        "                \n",
        "                # Store results\n",
        "                all_predictions.append(predicted.item())\n",
        "                all_true_labels.append(label.int().item())\n",
        "                fold_accuracies.append(1 if predicted.item() == label.int().item() else 0)\n",
        "\n",
        "    # Calculate overall statistics\n",
        "    overall_accuracy = np.mean(fold_accuracies)\n",
        "    correct_predictions = sum(fold_accuracies)\n",
        "    total_predictions = len(fold_accuracies)\n",
        "\n",
        "    print(f\"\\nCross-Validation Results:\")\n",
        "    print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")\n",
        "    print(f\"Correct Predictions: {correct_predictions}/{total_predictions}\")\n",
        "\n",
        "    # Additional metrics\n",
        "    from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "    precision = precision_score(all_true_labels, all_predictions, zero_division=0)\n",
        "    recall = recall_score(all_true_labels, all_predictions, zero_division=0)\n",
        "    f1 = f1_score(all_true_labels, all_predictions, zero_division=0)\n",
        "    cm = confusion_matrix(all_true_labels, all_predictions)\n",
        "\n",
        "    print(f\"Precision: {precision:.3f}\")\n",
        "    print(f\"Recall: {recall:.3f}\")\n",
        "    print(f\"F1-Score: {f1:.3f}\")\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_nn_model_maker():\n",
        "    # Model parameters\n",
        "    embedding_dim = 64\n",
        "    hidden_dim = 128\n",
        "    vocab_size = len(unique_characters)\n",
        "\n",
        "    return SimplePairNN(vocab_size, embedding_dim, hidden_dim)\n",
        "\n",
        "cv_test_model(simple_nn_model_maker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOO-CV Progress:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\lsm0147\\Documents\\Cognates\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "LOO-CV Progress: 100%|██████████| 10/10 [17:57<00:00, 107.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-Validation Results:\n",
            "Overall Accuracy: 77.13%\n",
            "Correct Predictions: 36461/47274\n",
            "Precision: 0.623\n",
            "Recall: 0.582\n",
            "F1-Score: 0.602\n",
            "Confusion Matrix:\n",
            "[[28278  4943]\n",
            " [ 5870  8183]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from transformer_stuff import TransformerCognateModel, UnbatchedWrapper\n",
        "\n",
        "def simple_nn_model_maker():\n",
        "    # Model parameters\n",
        "    embedding_dim = 64\n",
        "    hidden_dim = 128\n",
        "    vocab_size = len(unique_characters)\n",
        "\n",
        "    model = TransformerCognateModel(vocab_size, embedding_dim, hidden_dim)\n",
        "    return model\n",
        "    #return UnbatchedWrapper(model)\n",
        "\n",
        "cv_test_model(simple_nn_model_maker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_model = SimplePairNN(vocab_size, embedding_dim, hidden_dim)\n",
        "final_criterion = nn.BCELoss()\n",
        "final_optimizer = optim.Adam(final_model.parameters(), lr=0.001)\n",
        "\n",
        "final_dataset = SimpleCognateDataset(pairs, unique_characters, maxlen)\n",
        "final_loader = DataLoader(final_dataset, batch_size=32, shuffle=True, \n",
        "                         generator=torch.Generator(device='cuda'))\n",
        "\n",
        "for epoch in tqdm(range(5), desc=\"Training final model\"):\n",
        "    final_model.train()\n",
        "    total_loss = 0\n",
        "    for word1, word2, label in final_loader:\n",
        "        final_optimizer.zero_grad()\n",
        "        output = final_model(word1, word2).squeeze()\n",
        "        loss = final_criterion(output, label)\n",
        "        loss.backward()\n",
        "        final_optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Final model - Epoch {epoch+1}/5, Loss: {total_loss / len(final_loader):.4f}\")\n",
        "\n",
        "final_model.eval()\n",
        "final_predictions = []\n",
        "final_true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for word1, word2, label in tqdm(final_loader, desc=\"Evaluating final model\"):\n",
        "        output = final_model(word1, word2).squeeze()\n",
        "        predicted = (output > 0.5).int()\n",
        "        \n",
        "        # Handle both single samples and batches\n",
        "        if predicted.dim() == 0:\n",
        "            final_predictions.append(predicted.item())\n",
        "            final_true_labels.append(label.int().item())\n",
        "        else:\n",
        "            final_predictions.extend(predicted.cpu().numpy())\n",
        "            final_true_labels.extend(label.int().cpu().numpy())\n",
        "\n",
        "# Calculate final model metrics\n",
        "final_accuracy = np.mean(np.array(final_predictions) == np.array(final_true_labels))\n",
        "final_precision = precision_score(final_true_labels, final_predictions, zero_division=0)\n",
        "final_recall = recall_score(final_true_labels, final_predictions, zero_division=0)\n",
        "final_f1 = f1_score(final_true_labels, final_predictions, zero_division=0)\n",
        "final_cm = confusion_matrix(final_true_labels, final_predictions)\n",
        "\n",
        "print(f\"\\nFinal Model Performance (on all data):\")\n",
        "print(f\"Accuracy: {final_accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {final_precision:.3f}\")\n",
        "print(f\"Recall: {final_recall:.3f}\")\n",
        "print(f\"F1-Score: {final_f1:.3f}\")\n",
        "print(f\"Confusion Matrix:\")\n",
        "print(final_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_pair(word1, word2):\n",
        "    def encode(w):\n",
        "        char_to_idx = {char: i+1 for i, char in enumerate(unique_characters)}\n",
        "        idxs = [char_to_idx.get(c, 0) for c in w]\n",
        "        return idxs + [0] * (maxlen - len(idxs))\n",
        "\n",
        "    w1 = torch.tensor([encode(word1)], dtype=torch.long, device=device)\n",
        "    w2 = torch.tensor([encode(word2)], dtype=torch.long, device=device)\n",
        "    final_model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = final_model(w1, w2)\n",
        "    return \"Yes\" if out.item() > 0.5 else \"No\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://github.com/pytorch/examples/tree/main/word_language_model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
