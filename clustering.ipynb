{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_stuff import generate_all_clusters, score_cluster, create_groupings, evaluate_clusters\n",
    "\n",
    "def find_best_clustering(adj_matrix, conductance_weight=0.5, density_weight=0.5):\n",
    "    \"\"\"Find the best clustering using greedy approach.\"\"\"\n",
    "    n_nodes = adj_matrix.shape[0]\n",
    "    available_nodes = list(range(n_nodes))\n",
    "    clusters = []\n",
    "    \n",
    "    while len(available_nodes) > 1:\n",
    "        import math\n",
    "        max_cluster_size = min(math.floor(math.sqrt(n_nodes)), 8)\n",
    "        if max_cluster_size < 2:\n",
    "            break\n",
    "        \n",
    "        # Generate all possible clusters\n",
    "        possible_clusters = generate_all_clusters(available_nodes, max_cluster_size)\n",
    "        \n",
    "        best_cluster = None\n",
    "        best_score = -1\n",
    "        \n",
    "        # Find best cluster\n",
    "        from tqdm.notebook import tqdm\n",
    "        for cluster in tqdm(possible_clusters, desc=\"Possible clusters\", leave=False):\n",
    "            score = score_cluster(cluster, adj_matrix, conductance_weight, density_weight)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_cluster = cluster\n",
    "        \n",
    "        if best_cluster is None or best_score <= 0:\n",
    "            break\n",
    "        \n",
    "        # Add best cluster and remove its nodes from available\n",
    "        clusters.append(best_cluster)\n",
    "        available_nodes = [node for node in available_nodes if node not in best_cluster]\n",
    "    \n",
    "    # Add remaining nodes as singleton clusters\n",
    "    for node in available_nodes:\n",
    "        clusters.append([node])\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "def cluster_grouping(word_array, model, device='cpu'):\n",
    "    \"\"\"\n",
    "    Cluster a group of words using the model to create adjacency matrix.\n",
    "    \n",
    "    Args:\n",
    "        word_array: List of tensors representing IPA words\n",
    "        model: Trained transformer model\n",
    "        device: Device to run model on\n",
    "    \n",
    "    Returns:\n",
    "        List of clusters, where each cluster is a list of indices\n",
    "    \"\"\"\n",
    "    n_words = len(word_array)\n",
    "    \n",
    "    # Create adjacency matrix\n",
    "    adj_matrix = torch.zeros((n_words, n_words))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(n_words):\n",
    "            for j in range(i+1, n_words):\n",
    "                # Create word pair tensor\n",
    "                word_pair = torch.stack([word_array[i], word_array[j]], dim=0).unsqueeze(0).to(device)\n",
    "                \n",
    "                # Create masks (True for padding tokens)\n",
    "                mask1 = (word_array[i] == 0).unsqueeze(0).to(device)\n",
    "                mask2 = (word_array[j] == 0).unsqueeze(0).to(device)\n",
    "                word_pair_masks = torch.stack([mask1, mask2], dim=1).to(device)\n",
    "                \n",
    "                # Get similarity score\n",
    "                similarity = model(word_pair, word_pair_masks).item()\n",
    "                \n",
    "                # Fill both triangles of the matrix\n",
    "                adj_matrix[i, j] = similarity\n",
    "                adj_matrix[j, i] = similarity\n",
    "\n",
    "    # Find best clustering\n",
    "    predicted_clusters = find_best_clustering(adj_matrix)\n",
    "    \n",
    "    return predicted_clusters\n",
    "\n",
    "def cluster_and_evaluate_all_meanings(df, model, ipa_to_ids, device='cpu'):\n",
    "    \"\"\"Process all word meanings and evaluate clustering using the modular approach.\"\"\"\n",
    "    # Step 1: Preprocessing\n",
    "    groupings = create_groupings(df, ipa_to_ids)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Step 2 & 3: Clustering and Evaluation\n",
    "    from tqdm.notebook import tqdm\n",
    "    for meaning, (word_array, cognate_class_label_array) in tqdm(groupings.items(), total=len(groupings), desc=\"Groupings\"):\n",
    "        #print(f\"\\nProcessing meaning: {meaning}\")\n",
    "        #print(f\"Number of words: {len(word_array)}\")\n",
    "        \n",
    "        # Step 2: Clustering\n",
    "        predicted_clusters = cluster_grouping(word_array, model, device)\n",
    "        \n",
    "        # Step 3: Evaluation\n",
    "        evaluation_results = evaluate_clusters(predicted_clusters, cognate_class_label_array, meaning)\n",
    "        \n",
    "        results[meaning] = evaluation_results\n",
    "        \n",
    "        #print(f\"Predicted clusters: {predicted_clusters}\")\n",
    "        #print(f\"True classes: {cognate_class_label_array}\")\n",
    "        #print(f\"Accuracy: {evaluation_results['accuracy']:.3f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerCognateModel(\n",
       "  (embedder): Embedding(129, 34, padding_idx=0)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=34, out_features=34, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=34, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=34, bias=True)\n",
       "        (norm1): LayerNorm((34,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((34,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=68, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (cosine_similarity): CosineSimilarity()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data/ielexData.csv')\n",
    "\n",
    "# Create IPA to ID mapping\n",
    "import joblib\n",
    "ipa_embedder = joblib.load(\"data/embeddings/34.joblib\")\n",
    "ipa_to_ids = ipa_embedder.char_to_idx\n",
    "\n",
    "# Example of using the modular approach:\n",
    "from transformer_stuff import TransformerCognateModel\n",
    "model = torch.load('TransformerCognateModel_34.pt', weights_only=False)\n",
    "device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636dff2f7b914023b6a1443f6b1abef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating batches:   0%|          | 0/47274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bc188fe74541a4896a16905fe73cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing IELEX against GLED:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78     33221\n",
      "           1       0.48      0.45      0.46     14053\n",
      "\n",
      "    accuracy                           0.69     47274\n",
      "   macro avg       0.62      0.62      0.62     47274\n",
      "weighted avg       0.68      0.69      0.69     47274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "ielexPairsDf = pd.read_csv(\"data/ielexData.csv\")\n",
    "\n",
    "ielexPairsDf = ielexPairsDf[['Meaning', 'Phonological Form', 'cc']].dropna()\n",
    "ielexPairsDf.columns = ['meaning', 'word', 'cognate_class']\n",
    "\n",
    "ielexPairs = []\n",
    "\n",
    "for _, group in ielexPairsDf.groupby('meaning'):\n",
    "    entries = group.to_dict('records')\n",
    "    for w1, w2 in combinations(entries, 2):\n",
    "        word1 = str(w1['word'])\n",
    "        word2 = str(w2['word'])\n",
    "        label = int(w1['cognate_class'] == w2['cognate_class'])\n",
    "        ielexPairs.append((word1, word2, label))\n",
    "\n",
    "def preprocess(all_pairs, ipa_embedder, device):\n",
    "    from itertools import chain\n",
    "\n",
    "    max_length = 0\n",
    "    for pair in all_pairs:\n",
    "        for word in pair:\n",
    "            length = len(word)\n",
    "            if length > max_length:\n",
    "                max_length = length\n",
    "    \n",
    "    batches = torch.empty((len(all_pairs), 2, max_length), dtype=torch.int, device=device)\n",
    "    batches_masks = torch.zeros((len(all_pairs), 2, max_length), dtype=torch.bool, device=device)\n",
    "\n",
    "    from tqdm.notebook import tqdm\n",
    "    for pair_index, pair in tqdm(enumerate(all_pairs), total=len(all_pairs), desc=\"Creating batches\"):\n",
    "        for word_index, word in enumerate(pair):\n",
    "            for letter_index, letter in enumerate(word):\n",
    "                batches[pair_index, word_index, letter_index] = ipa_embedder.char_to_idx[letter]\n",
    "            \n",
    "            batches_masks[pair_index, word_index, len(word):] = True\n",
    "\n",
    "    return (batches, batches_masks, max_length)\n",
    "\n",
    "all_pairs = [row[:2] for row in ielexPairs]\n",
    "all_labels = [row[2] for row in ielexPairs]\n",
    "\n",
    "ldistance_operations, ldistance_masks, max_length = preprocess(all_pairs, ipa_embedder, device=device)\n",
    "test_data = list(zip(ldistance_operations, ldistance_masks))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "test_loader = DataLoader(test_data, batch_size=1600, generator=torch.Generator(device=torch.get_default_device().type))\n",
    "\n",
    "predicted_labels = []\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "for batch in tqdm(test_loader, desc=\"Testing IELEX against GLED\"):\n",
    "    batch_predicted_labels = model(*batch).squeeze()\n",
    "    batch_predicted_labels = (batch_predicted_labels > 0.5).int()\n",
    "    predicted_labels.extend(batch_predicted_labels.tolist())\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(all_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c183e5992680418399f1a4affad08ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groupings:   0%|          | 0/208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lsm0147\\Documents\\Cognates\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f37356b863f45a2b93622a844555d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/12926 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e98680f9c8445708437270d4126af4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/6175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8486c522be3e4f6ab29e506b7d0a6522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de53753bda249bc9d59935f211f097a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3061902732c546dcad6fa705161ed1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440871142d3b416a9dae1266dd7ec3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194a6cbc39ed474baaf4a05f200baced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/6175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6293d7f6dca84daf9272c660ac4dc4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9aaae0993d459c97120d5556dea63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962ebd21dda8449bb5cc07586aba59dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fc3543c32449f99188e3c9843ebbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bca2808805a45abacb2374f045e76cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/9086 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f86a1207664742b3d9309d54fe857c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/4029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a63eafd732e43b2b9b82a7d994f323e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/1456 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7075ab96b4b14ea4b0f149af817fd9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3a3990bee04726830944fc9f75dd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0f311ff29c4cbfa15d799369ee97c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f59e3331c994422b7ff394c3c79fec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/6175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e1011d3ac0400b889aa49f8a9ca7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02e8ba2b11a470b8e7a5fb1d8964aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231c8aeec42346cd9150f028c168e917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a66042107a454bb8cb43f2a5636217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f277d8171c68496988b0ae796d806359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8186cb447e340c3b03b5af0cd2f3977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11545a1fea524726911f29c522845fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8334276fd2c34cc6b9a0e11a2a14e3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/7525 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87065d9e3ac4f55b7e4f8d9cf4febfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/3196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321286bc92224c6bbf0a8e9b07b5fb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/1079 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d73e2ea5238452b99d127d4da3ed811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3b440a294c4f74b4772be770f0b723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420338371b1449a4bb50886293b69173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Possible clusters:   0%|          | 0/284240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Process a single meaning group\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# meaning = 'few'\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# if meaning in groupings:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Or process all meanings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m all_results = \u001b[43mcluster_and_evaluate_all_meanings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mipa_to_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36mcluster_and_evaluate_all_meanings\u001b[39m\u001b[34m(df, model, ipa_to_ids, device)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m meaning, (word_array, cognate_class_label_array) \u001b[38;5;129;01min\u001b[39;00m tqdm(groupings.items(), total=\u001b[38;5;28mlen\u001b[39m(groupings), desc=\u001b[33m\"\u001b[39m\u001b[33mGroupings\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m#print(f\"\\nProcessing meaning: {meaning}\")\u001b[39;00m\n\u001b[32m     94\u001b[39m     \u001b[38;5;66;03m#print(f\"Number of words: {len(word_array)}\")\u001b[39;00m\n\u001b[32m     95\u001b[39m \n\u001b[32m     96\u001b[39m     \u001b[38;5;66;03m# Step 2: Clustering\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     predicted_clusters = \u001b[43mcluster_grouping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m     \u001b[38;5;66;03m# Step 3: Evaluation\u001b[39;00m\n\u001b[32m    100\u001b[39m     evaluation_results = evaluate_clusters(predicted_clusters, cognate_class_label_array, meaning)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mcluster_grouping\u001b[39m\u001b[34m(word_array, model, device)\u001b[39m\n\u001b[32m     76\u001b[39m             adj_matrix[j, i] = similarity\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Find best clustering\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m predicted_clusters = \u001b[43mfind_best_clustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_clusters\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mfind_best_clustering\u001b[39m\u001b[34m(adj_matrix, conductance_weight, density_weight)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cluster \u001b[38;5;129;01min\u001b[39;00m tqdm(possible_clusters, desc=\u001b[33m\"\u001b[39m\u001b[33mPossible clusters\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     score = \u001b[43mscore_cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconductance_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m score > best_score:\n\u001b[32m     26\u001b[39m         best_score = score\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lsm0147\\Documents\\Cognates\\graph_stuff.py:100\u001b[39m, in \u001b[36mscore_cluster\u001b[39m\u001b[34m(cluster, adj, conductance_weight, density_weight)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cluster) <= \u001b[32m1\u001b[39m:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m cond_score = \u001b[43mconductance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m dens_score = density(cluster, adj)\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cond_score == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lsm0147\\Documents\\Cognates\\graph_stuff.py:71\u001b[39m, in \u001b[36mconductance\u001b[39m\u001b[34m(cluster, adj)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m cluster_set:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     inside += adj[i][j] / \u001b[32m2\u001b[39m  \u001b[38;5;66;03m# Divide by 2 to avoid double counting\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     73\u001b[39m     outside += adj[i][j]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Process a single meaning group\n",
    "# meaning = 'few'\n",
    "# if meaning in groupings:\n",
    "#     word_array, cognate_labels = groupings[meaning]\n",
    "#     clusters = cluster_grouping(word_array, model, device)\n",
    "#     results = evaluate_clusters(clusters, cognate_labels, meaning)\n",
    "#     print(f\"Results for '{meaning}': {results}\")\n",
    "\n",
    "# Or process all meanings\n",
    "all_results = cluster_and_evaluate_all_meanings(df, model, ipa_to_ids, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [r['accuracy'] for r in all_results.values()]\n",
    "print(f\"\\nOverall average accuracy: {np.mean(accuracies):.3f}\")\n",
    "\n",
    "f1s = [r['f1'] for r in all_results.values()]\n",
    "print(f\"\\nOverall f1 score: {np.mean(f1s):.3f}\")\n",
    "\n",
    "nmis = [r['nmi'] for r in all_results.values()]\n",
    "print(f\"\\nOverall nmi score: {np.mean(nmis):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from visualization_stuff import show_box_plot\n",
    "\n",
    "show_box_plot(accuracies, title=\"IELEX Clustering Accuracies\")\n",
    "show_box_plot(f1s, title=\"IELEX Clustering F1 Scores\")\n",
    "show_box_plot(nmis, title=\"IELEX Clustering NMI scores\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
